{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "single-connecticut",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import rmm\n",
    "import cudf\n",
    "import cugraph\n",
    "import numpy as np\n",
    "from math import ceil\n",
    "\n",
    "default_palette = [\n",
    "    # https://colorbrewer2.org/#type=diverging&scheme=Spectral&n=11\n",
    "    4288545090,\n",
    "    4292165199,\n",
    "    4294208835,\n",
    "    4294815329,\n",
    "    4294893707,\n",
    "    4294967231,\n",
    "    4293326232,\n",
    "    4289453476,\n",
    "    4284924581,\n",
    "    4281501885,\n",
    "    4284370850\n",
    "]\n",
    "\n",
    "\n",
    "def print_df(name, df):\n",
    "    print(str(name) + \" dtypes:\\n\" + str(df.dtypes))\n",
    "    print(str(name) + \":\\n\" + str(df))\n",
    "\n",
    "\n",
    "def category_to_color(categories, color_palette=None, cat_colors: dict = None):\n",
    "\n",
    "    if (cat_colors is not None):\n",
    "        # cats = cudf.Series.from_categorical(pandas.Categorical(categories, categories=list(cat_colors.keys()), ordered=True))\n",
    "        # cats = cudf.Series(categories).astype(\"categories\")\n",
    "\n",
    "        # cats = cats.cat.set_categories(list(cat_colors.keys()))\n",
    "        pass\n",
    "\n",
    "    if color_palette is None:\n",
    "        color_palette = default_palette\n",
    "    color_indices = cudf.Series(categories)\n",
    "    color_palette = cudf.Series(color_palette)\n",
    "\n",
    "    # Check if we need to convert from string to indices\n",
    "    if color_indices.dtype.type != np.uint32:\n",
    "        if (cat_colors is not None):\n",
    "            # Use the category names to convert to codes to ensure the proper indexes\n",
    "            color_indices = cudf.Series(categories,\n",
    "                                        dtype=\"category\").cat.set_categories(list(cat_colors.keys()))\n",
    "\n",
    "            assert not color_indices.isna().any()\n",
    "\n",
    "            # Now convert to uint32 codes\n",
    "            color_indices = color_indices.cat.codes.astype(np.uint32)\n",
    "        else:\n",
    "            # Auto factorize\n",
    "            color_indices = cudf.Series(categories.factorize()[0]).astype(np.uint32)\n",
    "\n",
    "    # Set the color_palette if we have a category dictionary\n",
    "    if (cat_colors is not None):\n",
    "        color_palette = cudf.Series(list(cat_colors.values()))\n",
    "\n",
    "    color_palettes = []\n",
    "    num_color_ids = color_indices.max() + 1\n",
    "    for i in range(ceil(num_color_ids / len(color_palette))):\n",
    "        color_palettes.append(color_palette)\n",
    "    return cudf.Series(\n",
    "        cudf.core.column.build_categorical_column(\n",
    "            ordered=True,\n",
    "            codes=color_indices._column,\n",
    "            categories=cudf.concat(color_palettes)[:num_color_ids],\n",
    "        ).as_numerical_column(dtype=np.uint32))\n",
    "\n",
    "\n",
    "def compute_edge_bundles(edges, id_, src, dst):\n",
    "    def drop_index(df):\n",
    "        return df.reset_index(drop=True)\n",
    "\n",
    "    def smoosh(df):\n",
    "        size = sum([df[x].dtype.itemsize for x in df])\n",
    "        data = drop_index(drop_index(df).stack()).data\n",
    "        dtype = cudf.utils.dtypes.min_unsigned_type(0, size * 8)\n",
    "        return cudf.core.column.NumericalColumn(data, dtype=dtype)\n",
    "\n",
    "    edges = cudf.DataFrame({\n",
    "        \"eid\": drop_index(edges[id_]),\n",
    "        \"src\": drop_index(edges[src]),\n",
    "        \"dst\": drop_index(edges[dst]),\n",
    "    })\n",
    "    # Create a duplicate table with:\n",
    "    # * all the [src, dst] in the upper half\n",
    "    # * all the [dst, src] pairs as the lower half, but flipped so dst->src, src->dst\n",
    "    bundles = drop_index(\n",
    "        cudf.DataFrame({\n",
    "            \"eid\": cudf.concat([edges[\"eid\"], edges[\"eid\"]], ignore_index=True),  # concat [src, dst] into the \"src\" column\n",
    "            \"src\": cudf.concat([edges[\"src\"], edges[\"dst\"]], ignore_index=True),  # concat [dst, src] into the \"dst\" column\n",
    "            \"dst\": cudf.concat([edges[\"dst\"], edges[\"src\"]], ignore_index=True),\n",
    "        }))\n",
    "\n",
    "    # Group the duplicated edgelist by [src, dst] and get the min edge id.\n",
    "    # Since all the [dst, src] pairs have been flipped to [src, dst], each\n",
    "    # edge with the same [src, dst] or [dst, src] vertices will be assigned\n",
    "    # the same bundle id\n",
    "    bundles = bundles.groupby([\"src\", \"dst\"]).agg({\"eid\": \"min\"}).reset_index().rename(columns={\"eid\": \"bid\"}, copy=False)\n",
    "\n",
    "    # Join the bundle ids into the edgelist\n",
    "    edges = edges.merge(bundles, on=[\"src\", \"dst\"], how=\"inner\")\n",
    "\n",
    "    # Determine each bundle\"s size and relative offset\n",
    "    lengths = edges[\"bid\"].value_counts(sort=False).sort_index()\n",
    "    bundles = lengths.index.to_series().unique()\n",
    "    offsets = lengths.cumsum() - lengths\n",
    "\n",
    "    # Join the bundle segment lengths + offsets into the edgelist\n",
    "    edges = edges.merge(cudf.DataFrame({\n",
    "        \"bid\": drop_index(bundles.astype(np.uint32)),\n",
    "        \"start\": drop_index(offsets.astype(np.uint32)),\n",
    "        \"count\": drop_index(lengths.astype(np.uint32)),\n",
    "    }),\n",
    "                        on=\"bid\",\n",
    "                        how=\"left\")\n",
    "\n",
    "    # Determine each edge's index relative to its bundle\n",
    "    edges = drop_index(edges.sort_values(by=\"bid\"))\n",
    "    edges[\"index\"] = edges.index.to_series() - edges[\"start\"]\n",
    "    edges[\"index\"] = edges[\"index\"].astype(np.uint32)\n",
    "\n",
    "    # Re-sort the edgelist by edge id and cleanup\n",
    "    edges = drop_index(edges.sort_values(by=\"eid\"))\n",
    "    edges = edges.rename(columns={\"eid\": \"id\"}, copy=False)\n",
    "    edges = edges[[\"id\", \"src\", \"dst\", \"index\", \"count\"]]\n",
    "\n",
    "    return {\n",
    "        \"edge\": smoosh(edges[[\"src\", \"dst\"]]).astype(np.uint64),\n",
    "        \"bundle\": smoosh(edges[[\"index\", \"count\"]]).astype(np.uint64),\n",
    "    }\n",
    "\n",
    "\n",
    "def from_cudf_edgelist(df, source=\"src\", target=\"dst\"):\n",
    "    \"\"\"\n",
    "    Construct an enhanced graph from a cuDF edgelist that doesn't collapse\n",
    "    duplicate edges and includes columns for node degree and edge bundle.\n",
    "    \"\"\"\n",
    "    def drop_index(df):\n",
    "        return df.reset_index(drop=True)\n",
    "\n",
    "    def smoosh(df):\n",
    "        size = sum([df[x].dtype.itemsize for x in df])\n",
    "        data = drop_index(drop_index(df).stack()).data\n",
    "        dtype = cudf.utils.dtypes.min_unsigned_type(0, size * 8)\n",
    "        return cudf.core.column.NumericalColumn(data, dtype=dtype)\n",
    "\n",
    "    def make_nodes(df, src, dst):\n",
    "        nodes = drop_index(df[src].append(df[dst], ignore_index=True).unique())\n",
    "        ids = drop_index(cudf.Series(nodes.factorize()[0])).astype(np.uint32)\n",
    "        return drop_index(cudf.DataFrame({\"id\": ids, \"node\": nodes}).sort_values(by=\"id\"))\n",
    "\n",
    "    def make_edges(df, src, dst, nodes):\n",
    "        def join(edges, nodes, col):\n",
    "            edges = edges.set_index(col, drop=True)\n",
    "            nodes = nodes.set_index(\"node\", drop=True)\n",
    "            edges = edges.join(nodes).sort_values(by=\"eid\")\n",
    "            edges = edges.rename(columns={\"id\": col}, copy=False)\n",
    "            return drop_index(edges)\n",
    "\n",
    "        edges = df.reset_index().rename(columns={\"index\": \"eid\"}, copy=False)\n",
    "        edges = join(join(edges.assign(src=df[src], dst=df[dst]), nodes, \"src\"), nodes, \"dst\")\n",
    "        return drop_index(edges.rename(columns={\"eid\": \"id\"}, copy=False))\n",
    "\n",
    "    df = drop_index(df)\n",
    "    graph = cugraph.MultiDiGraph()\n",
    "    nodes = make_nodes(df, source, target)\n",
    "    edges = make_edges(df, source, target, nodes)\n",
    "    graph.edgelist = cugraph.Graph.EdgeList(edges[\"src\"], edges[\"dst\"])\n",
    "    nodes = nodes.set_index(\"id\", drop=False).join(graph.degree().set_index(\"vertex\"))\n",
    "    return graph, drop_index(nodes.sort_index()), edges\n",
    "\n",
    "\n",
    "def annotate_nodes(graph, nodes, edges):\n",
    "    return nodes.assign(\n",
    "        # add node names\n",
    "        name=nodes[\"name\"] if \"name\" in nodes else nodes[\"id\"],\n",
    "        # add node sizes\n",
    "        size=(nodes[\"degree\"].scale() * (50 - 2) + 2).astype(np.uint8),\n",
    "        # add node colors\n",
    "        color=category_to_color(\n",
    "            cugraph.spectralBalancedCutClustering(graph, min(9, graph.number_of_nodes() -\n",
    "                                                             1)).sort_values(by=\"vertex\").reset_index(drop=True)[\"cluster\"],\n",
    "            color_palette=[\n",
    "                # Make all nodes white\n",
    "                4294967295\n",
    "                #                 # https://colorbrewer2.org/#type=diverging&scheme=Spectral&n=9\n",
    "                #                 4292165199, 4294208835,\n",
    "                #                 4294815329, 4294893707,\n",
    "                #                 4294967231, 4293326232,\n",
    "                #                 4289453476, 4284924581,\n",
    "                #                 4281501885\n",
    "            ]))\n",
    "\n",
    "\n",
    "def annotate_edges(graph, nodes, edges):\n",
    "    def drop_index(df):\n",
    "        return df.reset_index(drop=True)\n",
    "\n",
    "    def smoosh(df):\n",
    "        size = sum([df[x].dtype.itemsize for x in df])\n",
    "        data = drop_index(drop_index(df).stack()).data\n",
    "        dtype = cudf.utils.dtypes.min_unsigned_type(0, size * 8)\n",
    "        return cudf.core.column.NumericalColumn(data, dtype=dtype)\n",
    "\n",
    "    def edge_colors(nodes, edges, col):\n",
    "        edges = edges[[\"id\", col]].set_index(col, drop=True)\n",
    "        nodes = nodes[[\"id\", \"color\"]].set_index(\"id\", drop=True)\n",
    "        return drop_index(edges.join(nodes).sort_values(by=\"id\")[\"color\"])\n",
    "\n",
    "    return edges.assign(\n",
    "        # add edge names\n",
    "        name=edges[\"name\"] if \"name\" in edges else edges[\"id\"],\n",
    "        # add edge colors\n",
    "        color=smoosh(cudf.DataFrame({\n",
    "            \"src\": edge_colors(nodes, edges, \"src\"),\n",
    "            \"dst\": edge_colors(nodes, edges, \"dst\"),\n",
    "        })))\n",
    "\n",
    "\n",
    "def make_capwin_graph(df):\n",
    "    def drop_index(df):\n",
    "        return df.reset_index(drop=True)\n",
    "\n",
    "    def smoosh(df):\n",
    "        size = sum([df[x].dtype.itemsize for x in df])\n",
    "        data = drop_index(drop_index(df).stack()).data\n",
    "        dtype = cudf.utils.dtypes.min_unsigned_type(0, size * 8)\n",
    "        return cudf.core.column.NumericalColumn(data, dtype=dtype)\n",
    "\n",
    "    def add_edge_colors(edges, category):\n",
    "        colors = drop_index(\n",
    "            category_to_color(\n",
    "                edges[category],\n",
    "                color_palette=[\n",
    "                    #     FALSE,      TRUE\n",
    "                    # 268435455, 268369920\n",
    "\n",
    "                    #    FALSE,       TRUE\n",
    "                    # 33554431, 4293138972\n",
    "\n",
    "                    #    ADDRESS   AUTH KEYS CREDENTIALS       EMAIL      FALSE\n",
    "                    # 4294967091, 4294410687, 4293138972, 4281827000,  33554431\n",
    "                    0x0fffeda0,  # address 268430752\n",
    "                    0x0ffed976,  # bank_acct 268360054\n",
    "                    0x0ffeb24c,  # email\n",
    "                    0x0ffd8d3c,  # govt_id\n",
    "                    0x0ffc4e2a,  # name\n",
    "                    0x01ffffff,  # none 33554431\n",
    "                    0x0fe31a1c,  # phone_num\n",
    "                    0x0fbd0026,  # secret_keys\n",
    "                    0x0f800026,  # user\n",
    "                ],\n",
    "                cat_colors={\n",
    "                    \"address\": 0x1effff5f,\n",
    "                    \"bank_acct\": 0x1effff5f,\n",
    "                    \"credit_card\": 0x1effff5f,\n",
    "                    \"email\": 0x1effff5f,\n",
    "                    \"govt_id\": 0x1effff5f,\n",
    "                    \"name\": 0x1effff5f,\n",
    "                    \"none\": 0x06ffffff,\n",
    "                    \"password\": 0x1effff5f,\n",
    "                    \"phone_num\": 0x1effff5f,\n",
    "                    \"secret_keys\": 0x80ff0000,\n",
    "                    \"user\": 0x1effff5f,\n",
    "                }).astype(np.uint32))\n",
    "        return edges.assign(color=smoosh(cudf.DataFrame({\n",
    "            \"src\": drop_index(colors), \"dst\": drop_index(colors)\n",
    "        })).astype(np.uint64),\n",
    "                            src_color=colors)\n",
    "\n",
    "    # Create graph\n",
    "    graph, nodes, edges = from_cudf_edgelist(df, \"src_ip\", \"dest_ip\")\n",
    "    # Add vis components\n",
    "    nodes = nodes.rename(columns={\"node\": \"name\"}, copy=False)\n",
    "    nodes = annotate_nodes(graph, nodes, edges)\n",
    "    # add edge colors\n",
    "    edges = add_edge_colors(edges, \"pii\")\n",
    "    # add edge names\n",
    "    edges[\"name\"] = edges[\"src_ip\"] + \" -> \" + edges[\"dest_ip\"] + (\"\\nSI: \" + edges[\"pii\"]).replace(\"\\nSI: FALSE\", \"\")\n",
    "    return graph, nodes, edges\n",
    "\n",
    "\n",
    "def make_capwin_dataset(start, end, src_path, dst_path):\n",
    "    def arange(size, dtype=\"uint32\"):\n",
    "        return cudf.core.index.RangeIndex(0, size).to_series().astype(dtype)\n",
    "\n",
    "    def relabel_nodes(nodesA, nodesB):\n",
    "        nodesA = nodesA.rename(columns={\"id\": \"lhs_id\"}, copy=False).set_index(\"name\", drop=True)\n",
    "        nodesB = nodesB.rename(columns={\"id\": \"rhs_id\"}, copy=False).set_index(\"name\", drop=False)\n",
    "        nodes = nodesA.join(nodesB, how=\"outer\", sort=True).sort_values(by=\"lhs_id\").reset_index(drop=True)\n",
    "        nodes = nodes.reset_index().rename(columns={\"index\": \"id\"}, copy=False)\n",
    "        nodes = nodes.drop(columns=[\"lhs_id\"]).rename(columns={\"rhs_id\": \"remap\"}, copy=False)\n",
    "        return nodes.reset_index(drop=True).sort_values(by=\"id\").reset_index(drop=True).astype({\"id\": np.uint32})\n",
    "\n",
    "    def relabel_edges(edgesA, edgesB, nodes):\n",
    "        def remap(edges, nodes, col):\n",
    "            edges = edges.set_index(col)\n",
    "            nodes = nodes.rename(columns={\"id\": col}, copy=False)\n",
    "            nodes = nodes.set_index(\"remap\")\n",
    "            return edges.join(nodes, sort=True).reset_index(drop=True)\n",
    "\n",
    "        return remap(remap(edgesB, nodes, \"src\"), nodes,\n",
    "                     \"dst\").drop(columns=[\"id\"]).sort_values(by=[\"src\", \"dst\"]).reset_index(drop=True).reset_index().rename(\n",
    "                         columns={\"index\": \"id\"}, copy=False)\n",
    "\n",
    "    df, nodes, edges = (cudf.DataFrame(), None, None)\n",
    "\n",
    "    for i in range(start, end):\n",
    "        print(f\"reading {src_path}/{i}.0.csv\")\n",
    "        try:\n",
    "            df2 = cudf.read_csv(\n",
    "                f\"{src_path}/{i}.0.csv\",\n",
    "                header=0,\n",
    "                parse_dates=[1],\n",
    "                usecols=[2, 3, 6, 7],\n",
    "                dtype=[\n",
    "                    \"int32\",  # index\n",
    "                    \"datetime64[ms]\",  # timestamp\n",
    "                    \"str\",  # src_ip\n",
    "                    \"str\",  # dest_ip\n",
    "                    \"int32\",  # src_port\n",
    "                    \"int32\",  # dest_port\n",
    "                    \"str\",  # pii\n",
    "                    \"str\", # data\n",
    "                ]).reset_index(drop=True)\n",
    "        except Exception:\n",
    "            # print(f\"missing {src_path}/{i}.0.csv\")\n",
    "            df2 = None\n",
    "\n",
    "        # print(f\"read {src_path}/{i}.0.csv\")\n",
    "        if (df2 is not None):\n",
    "            if \"si\" in df2:\n",
    "                df2 = df2.rename(columns={\"si\": \"pii\"}, copy=False)\n",
    "\n",
    "            df = cudf.concat([df.reset_index(drop=True), df2],\n",
    "                             ignore_index=True).reset_index(drop=True).sort_values(by=[\"src_ip\", \"dest_ip\"]).reset_index(drop=True)\n",
    "\n",
    "        results = make_capwin_graph(df[[\"src_ip\", \"dest_ip\", \"pii\", \"data\"]])\n",
    "\n",
    "        if i == start:\n",
    "            nodes = results[1][[\"id\", \"name\", \"degree\", \"size\", \"color\"]]\n",
    "            edges = results[2][[\"id\", \"name\", \"src\", \"dst\", \"color\", \"data\"]]\n",
    "        else:\n",
    "            nodes = relabel_nodes(nodes[[\"id\", \"name\"]], results[1][[\"id\", \"name\", \"degree\", \"size\", \"color\"]])\n",
    "            edges = relabel_edges(edges[[\"id\", \"name\", \"src\", \"dst\", \"color\", \"data\"]],\n",
    "                                  results[2][[\"id\", \"name\", \"src\", \"dst\", \"color\", \"data\"]],\n",
    "                                  nodes[[\"id\", \"remap\"]])\n",
    "\n",
    "        edges = edges.assign(**compute_edge_bundles(edges, \"id\", \"src\", \"dst\"))\n",
    "\n",
    "        nodes_out = nodes[[\"name\", \"id\", \"color\", \"size\"]]\n",
    "        edges_out = edges[[\"name\", \"src\", \"dst\", \"edge\", \"color\", \"bundle\", \"data\"]]\n",
    "\n",
    "        nodes_out.to_csv(f\"{dst_path}/{i - start}.0.nodes.csv\", index=False)\n",
    "        edges_out.to_csv(f\"{dst_path}/{i - start}.0.edges.csv\", index=False)\n",
    "\n",
    "    # Print all the PII values at the end so we can map the edge colors\n",
    "    # print(df[\"pii\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "owned-valuation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading ../viz_frames/1059.0.csv\n",
      "reading ../viz_frames/1060.0.csv\n",
      "reading ../viz_frames/1061.0.csv\n",
      "reading ../viz_frames/1062.0.csv\n",
      "reading ../viz_frames/1063.0.csv\n",
      "reading ../viz_frames/1064.0.csv\n",
      "reading ../viz_frames/1065.0.csv\n",
      "reading ../viz_frames/1066.0.csv\n",
      "reading ../viz_frames/1067.0.csv\n",
      "reading ../viz_frames/1068.0.csv\n",
      "reading ../viz_frames/1069.0.csv\n",
      "reading ../viz_frames/1070.0.csv\n",
      "reading ../viz_frames/1071.0.csv\n",
      "reading ../viz_frames/1072.0.csv\n",
      "reading ../viz_frames/1073.0.csv\n",
      "reading ../viz_frames/1074.0.csv\n",
      "reading ../viz_frames/1075.0.csv\n",
      "reading ../viz_frames/1076.0.csv\n",
      "reading ../viz_frames/1077.0.csv\n",
      "reading ../viz_frames/1078.0.csv\n",
      "reading ../viz_frames/1079.0.csv\n",
      "reading ../viz_frames/1080.0.csv\n",
      "reading ../viz_frames/1081.0.csv\n",
      "reading ../viz_frames/1082.0.csv\n",
      "reading ../viz_frames/1083.0.csv\n",
      "reading ../viz_frames/1084.0.csv\n",
      "reading ../viz_frames/1085.0.csv\n",
      "reading ../viz_frames/1086.0.csv\n",
      "reading ../viz_frames/1087.0.csv\n",
      "reading ../viz_frames/1088.0.csv\n",
      "reading ../viz_frames/1089.0.csv\n",
      "reading ../viz_frames/1090.0.csv\n",
      "reading ../viz_frames/1091.0.csv\n",
      "reading ../viz_frames/1092.0.csv\n",
      "reading ../viz_frames/1093.0.csv\n",
      "reading ../viz_frames/1094.0.csv\n",
      "reading ../viz_frames/1095.0.csv\n",
      "reading ../viz_frames/1096.0.csv\n",
      "reading ../viz_frames/1097.0.csv\n",
      "reading ../viz_frames/1098.0.csv\n",
      "reading ../viz_frames/1099.0.csv\n",
      "reading ../viz_frames/1100.0.csv\n",
      "reading ../viz_frames/1101.0.csv\n",
      "reading ../viz_frames/1102.0.csv\n",
      "reading ../viz_frames/1103.0.csv\n",
      "reading ../viz_frames/1104.0.csv\n",
      "reading ../viz_frames/1105.0.csv\n",
      "reading ../viz_frames/1106.0.csv\n",
      "reading ../viz_frames/1107.0.csv\n",
      "reading ../viz_frames/1108.0.csv\n",
      "reading ../viz_frames/1109.0.csv\n",
      "reading ../viz_frames/1110.0.csv\n",
      "reading ../viz_frames/1111.0.csv\n",
      "reading ../viz_frames/1112.0.csv\n",
      "reading ../viz_frames/1113.0.csv\n",
      "reading ../viz_frames/1114.0.csv\n",
      "reading ../viz_frames/1115.0.csv\n",
      "reading ../viz_frames/1116.0.csv\n",
      "reading ../viz_frames/1117.0.csv\n",
      "reading ../viz_frames/1118.0.csv\n",
      "reading ../viz_frames/1119.0.csv\n",
      "reading ../viz_frames/1120.0.csv\n",
      "reading ../viz_frames/1121.0.csv\n",
      "reading ../viz_frames/1122.0.csv\n",
      "reading ../viz_frames/1123.0.csv\n",
      "reading ../viz_frames/1124.0.csv\n",
      "reading ../viz_frames/1125.0.csv\n",
      "reading ../viz_frames/1126.0.csv\n",
      "reading ../viz_frames/1127.0.csv\n",
      "reading ../viz_frames/1128.0.csv\n",
      "reading ../viz_frames/1129.0.csv\n",
      "reading ../viz_frames/1130.0.csv\n",
      "reading ../viz_frames/1131.0.csv\n",
      "reading ../viz_frames/1132.0.csv\n",
      "reading ../viz_frames/1133.0.csv\n",
      "reading ../viz_frames/1134.0.csv\n",
      "reading ../viz_frames/1135.0.csv\n",
      "reading ../viz_frames/1136.0.csv\n",
      "reading ../viz_frames/1137.0.csv\n",
      "reading ../viz_frames/1138.0.csv\n",
      "reading ../viz_frames/1139.0.csv\n",
      "reading ../viz_frames/1140.0.csv\n",
      "reading ../viz_frames/1141.0.csv\n",
      "reading ../viz_frames/1142.0.csv\n",
      "reading ../viz_frames/1143.0.csv\n",
      "reading ../viz_frames/1144.0.csv\n",
      "reading ../viz_frames/1145.0.csv\n",
      "reading ../viz_frames/1146.0.csv\n",
      "reading ../viz_frames/1147.0.csv\n",
      "reading ../viz_frames/1148.0.csv\n",
      "reading ../viz_frames/1149.0.csv\n",
      "reading ../viz_frames/1150.0.csv\n",
      "reading ../viz_frames/1151.0.csv\n",
      "reading ../viz_frames/1152.0.csv\n",
      "reading ../viz_frames/1153.0.csv\n",
      "reading ../viz_frames/1154.0.csv\n",
      "reading ../viz_frames/1155.0.csv\n",
      "reading ../viz_frames/1156.0.csv\n",
      "reading ../viz_frames/1157.0.csv\n",
      "reading ../viz_frames/1158.0.csv\n",
      "reading ../viz_frames/1159.0.csv\n",
      "reading ../viz_frames/1160.0.csv\n",
      "reading ../viz_frames/1161.0.csv\n",
      "reading ../viz_frames/1162.0.csv\n",
      "reading ../viz_frames/1163.0.csv\n",
      "reading ../viz_frames/1164.0.csv\n",
      "reading ../viz_frames/1165.0.csv\n",
      "reading ../viz_frames/1166.0.csv\n",
      "reading ../viz_frames/1167.0.csv\n",
      "reading ../viz_frames/1168.0.csv\n",
      "reading ../viz_frames/1169.0.csv\n",
      "reading ../viz_frames/1170.0.csv\n",
      "reading ../viz_frames/1171.0.csv\n",
      "reading ../viz_frames/1172.0.csv\n",
      "reading ../viz_frames/1173.0.csv\n",
      "reading ../viz_frames/1174.0.csv\n",
      "reading ../viz_frames/1175.0.csv\n",
      "reading ../viz_frames/1176.0.csv\n",
      "reading ../viz_frames/1177.0.csv\n",
      "reading ../viz_frames/1178.0.csv\n",
      "reading ../viz_frames/1179.0.csv\n",
      "reading ../viz_frames/1180.0.csv\n",
      "reading ../viz_frames/1181.0.csv\n",
      "reading ../viz_frames/1182.0.csv\n",
      "reading ../viz_frames/1183.0.csv\n",
      "reading ../viz_frames/1184.0.csv\n",
      "reading ../viz_frames/1185.0.csv\n",
      "reading ../viz_frames/1186.0.csv\n",
      "reading ../viz_frames/1187.0.csv\n",
      "reading ../viz_frames/1188.0.csv\n",
      "reading ../viz_frames/1189.0.csv\n",
      "reading ../viz_frames/1190.0.csv\n",
      "reading ../viz_frames/1191.0.csv\n",
      "reading ../viz_frames/1192.0.csv\n",
      "reading ../viz_frames/1193.0.csv\n",
      "reading ../viz_frames/1194.0.csv\n",
      "reading ../viz_frames/1195.0.csv\n",
      "reading ../viz_frames/1196.0.csv\n",
      "reading ../viz_frames/1197.0.csv\n",
      "reading ../viz_frames/1198.0.csv\n",
      "reading ../viz_frames/1199.0.csv\n",
      "reading ../viz_frames/1200.0.csv\n",
      "reading ../viz_frames/1201.0.csv\n",
      "reading ../viz_frames/1202.0.csv\n",
      "reading ../viz_frames/1203.0.csv\n",
      "reading ../viz_frames/1204.0.csv\n",
      "reading ../viz_frames/1205.0.csv\n",
      "reading ../viz_frames/1206.0.csv\n",
      "reading ../viz_frames/1207.0.csv\n",
      "reading ../viz_frames/1208.0.csv\n",
      "reading ../viz_frames/1209.0.csv\n",
      "reading ../viz_frames/1210.0.csv\n",
      "reading ../viz_frames/1211.0.csv\n",
      "reading ../viz_frames/1212.0.csv\n",
      "reading ../viz_frames/1213.0.csv\n",
      "reading ../viz_frames/1214.0.csv\n",
      "reading ../viz_frames/1215.0.csv\n",
      "reading ../viz_frames/1216.0.csv\n",
      "reading ../viz_frames/1217.0.csv\n",
      "reading ../viz_frames/1218.0.csv\n",
      "reading ../viz_frames/1219.0.csv\n",
      "reading ../viz_frames/1220.0.csv\n",
      "reading ../viz_frames/1221.0.csv\n",
      "reading ../viz_frames/1222.0.csv\n",
      "reading ../viz_frames/1223.0.csv\n",
      "reading ../viz_frames/1224.0.csv\n",
      "reading ../viz_frames/1225.0.csv\n",
      "reading ../viz_frames/1226.0.csv\n",
      "reading ../viz_frames/1227.0.csv\n",
      "reading ../viz_frames/1228.0.csv\n",
      "reading ../viz_frames/1229.0.csv\n",
      "reading ../viz_frames/1230.0.csv\n",
      "reading ../viz_frames/1231.0.csv\n",
      "reading ../viz_frames/1232.0.csv\n",
      "reading ../viz_frames/1233.0.csv\n",
      "reading ../viz_frames/1234.0.csv\n",
      "reading ../viz_frames/1235.0.csv\n",
      "reading ../viz_frames/1236.0.csv\n",
      "reading ../viz_frames/1237.0.csv\n",
      "reading ../viz_frames/1238.0.csv\n",
      "reading ../viz_frames/1239.0.csv\n",
      "reading ../viz_frames/1240.0.csv\n",
      "reading ../viz_frames/1241.0.csv\n",
      "reading ../viz_frames/1242.0.csv\n",
      "reading ../viz_frames/1243.0.csv\n",
      "reading ../viz_frames/1244.0.csv\n",
      "reading ../viz_frames/1245.0.csv\n",
      "reading ../viz_frames/1246.0.csv\n",
      "reading ../viz_frames/1247.0.csv\n",
      "reading ../viz_frames/1248.0.csv\n",
      "reading ../viz_frames/1249.0.csv\n",
      "reading ../viz_frames/1250.0.csv\n",
      "reading ../viz_frames/1251.0.csv\n",
      "reading ../viz_frames/1252.0.csv\n",
      "reading ../viz_frames/1253.0.csv\n",
      "reading ../viz_frames/1254.0.csv\n",
      "reading ../viz_frames/1255.0.csv\n",
      "reading ../viz_frames/1256.0.csv\n",
      "reading ../viz_frames/1257.0.csv\n",
      "reading ../viz_frames/1258.0.csv\n",
      "reading ../viz_frames/1259.0.csv\n",
      "reading ../viz_frames/1260.0.csv\n",
      "reading ../viz_frames/1261.0.csv\n",
      "reading ../viz_frames/1262.0.csv\n",
      "reading ../viz_frames/1263.0.csv\n",
      "reading ../viz_frames/1264.0.csv\n",
      "reading ../viz_frames/1265.0.csv\n",
      "reading ../viz_frames/1266.0.csv\n",
      "reading ../viz_frames/1267.0.csv\n",
      "reading ../viz_frames/1268.0.csv\n",
      "reading ../viz_frames/1269.0.csv\n",
      "reading ../viz_frames/1270.0.csv\n",
      "reading ../viz_frames/1271.0.csv\n",
      "reading ../viz_frames/1272.0.csv\n",
      "reading ../viz_frames/1273.0.csv\n",
      "reading ../viz_frames/1274.0.csv\n",
      "reading ../viz_frames/1275.0.csv\n",
      "reading ../viz_frames/1276.0.csv\n",
      "reading ../viz_frames/1277.0.csv\n",
      "reading ../viz_frames/1278.0.csv\n",
      "reading ../viz_frames/1279.0.csv\n",
      "reading ../viz_frames/1280.0.csv\n",
      "reading ../viz_frames/1281.0.csv\n",
      "reading ../viz_frames/1282.0.csv\n",
      "reading ../viz_frames/1283.0.csv\n",
      "reading ../viz_frames/1284.0.csv\n",
      "reading ../viz_frames/1285.0.csv\n",
      "reading ../viz_frames/1286.0.csv\n",
      "reading ../viz_frames/1287.0.csv\n",
      "reading ../viz_frames/1288.0.csv\n",
      "reading ../viz_frames/1289.0.csv\n",
      "reading ../viz_frames/1290.0.csv\n",
      "reading ../viz_frames/1291.0.csv\n",
      "reading ../viz_frames/1292.0.csv\n",
      "reading ../viz_frames/1293.0.csv\n",
      "reading ../viz_frames/1294.0.csv\n",
      "reading ../viz_frames/1295.0.csv\n",
      "reading ../viz_frames/1296.0.csv\n",
      "reading ../viz_frames/1297.0.csv\n",
      "reading ../viz_frames/1298.0.csv\n",
      "reading ../viz_frames/1299.0.csv\n",
      "reading ../viz_frames/1300.0.csv\n",
      "reading ../viz_frames/1301.0.csv\n",
      "reading ../viz_frames/1302.0.csv\n",
      "reading ../viz_frames/1303.0.csv\n",
      "reading ../viz_frames/1304.0.csv\n",
      "reading ../viz_frames/1305.0.csv\n",
      "reading ../viz_frames/1306.0.csv\n",
      "reading ../viz_frames/1307.0.csv\n",
      "reading ../viz_frames/1308.0.csv\n",
      "reading ../viz_frames/1309.0.csv\n",
      "reading ../viz_frames/1310.0.csv\n",
      "reading ../viz_frames/1311.0.csv\n",
      "reading ../viz_frames/1312.0.csv\n",
      "reading ../viz_frames/1313.0.csv\n",
      "reading ../viz_frames/1314.0.csv\n",
      "reading ../viz_frames/1315.0.csv\n",
      "reading ../viz_frames/1316.0.csv\n",
      "reading ../viz_frames/1317.0.csv\n",
      "reading ../viz_frames/1318.0.csv\n",
      "reading ../viz_frames/1319.0.csv\n",
      "reading ../viz_frames/1320.0.csv\n",
      "reading ../viz_frames/1321.0.csv\n",
      "reading ../viz_frames/1322.0.csv\n",
      "reading ../viz_frames/1323.0.csv\n",
      "reading ../viz_frames/1324.0.csv\n",
      "reading ../viz_frames/1325.0.csv\n",
      "reading ../viz_frames/1326.0.csv\n",
      "reading ../viz_frames/1327.0.csv\n",
      "reading ../viz_frames/1328.0.csv\n",
      "reading ../viz_frames/1329.0.csv\n",
      "reading ../viz_frames/1330.0.csv\n",
      "reading ../viz_frames/1331.0.csv\n",
      "reading ../viz_frames/1332.0.csv\n",
      "reading ../viz_frames/1333.0.csv\n",
      "reading ../viz_frames/1334.0.csv\n",
      "reading ../viz_frames/1335.0.csv\n",
      "reading ../viz_frames/1336.0.csv\n",
      "reading ../viz_frames/1337.0.csv\n",
      "reading ../viz_frames/1338.0.csv\n",
      "reading ../viz_frames/1339.0.csv\n",
      "reading ../viz_frames/1340.0.csv\n",
      "reading ../viz_frames/1341.0.csv\n",
      "reading ../viz_frames/1342.0.csv\n",
      "reading ../viz_frames/1343.0.csv\n",
      "reading ../viz_frames/1344.0.csv\n",
      "reading ../viz_frames/1345.0.csv\n",
      "reading ../viz_frames/1346.0.csv\n",
      "reading ../viz_frames/1347.0.csv\n",
      "reading ../viz_frames/1348.0.csv\n",
      "reading ../viz_frames/1349.0.csv\n",
      "reading ../viz_frames/1350.0.csv\n",
      "reading ../viz_frames/1351.0.csv\n",
      "reading ../viz_frames/1352.0.csv\n",
      "reading ../viz_frames/1353.0.csv\n",
      "reading ../viz_frames/1354.0.csv\n",
      "reading ../viz_frames/1355.0.csv\n",
      "reading ../viz_frames/1356.0.csv\n",
      "reading ../viz_frames/1357.0.csv\n",
      "reading ../viz_frames/1358.0.csv\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "output_dir = \"./output\"\n",
    "if (os.path.exists(output_dir)):\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "os.makedirs(\"./output\", exist_ok=True)\n",
    "make_capwin_dataset(1059,\n",
    "                    1359,\n",
    "                    \"../viz_frames\",\n",
    "                    output_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "criminal-geology",
   "metadata": {},
   "outputs": [],
   "source": [
    "[int('%02x%02x%02x%02x' % x, 16) for x in default_palette_hex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "romantic-attack",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-bc928d0bf57f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"pii\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.groupby(\"pii\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-depth",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
