{
   // Use IntelliSense to learn about possible attributes.
   // Hover to view descriptions of existing attributes.
   // For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387
   "version": "0.2.0",
   "configurations": [
      {
         "name": "Python: Current File",
         "type": "python",
         "request": "launch",
         "program": "${file}",
         "console": "integratedTerminal",
         "cwd": "${workspaceFolder}"
      },
      {
         "name": "Python: Run Network Generator",
         "type": "python",
         "request": "launch",
         "program": "${workspaceFolder}/.tmp/kafka-producer/main.py",
         "console": "integratedTerminal",
         "cwd": "${workspaceFolder}/.tmp/kafka-producer",
         "args": [
            "-m",
            "produce",
            "-n",
            "./network",
            "-i",
            "/home/mdemoret/Repos/rapids/cyber-dev/.tmp/dataset4/pcap_dump_pre_class.json",
            "-j",
            "1200",
            "-t",
            "test_pcap"
         ],
         "env": {
            "KAFKA_BROKER_SERVERS": "172.17.0.1:49161,172.17.0.1:49160,172.17.0.1:49159",
         }
      },
      {
         "name": "Python: Run Pipeline",
         "type": "python",
         "request": "launch",
         "program": "${workspaceFolder}/cli.py",
         "console": "integratedTerminal",
         "justMyCode": false,
         "cwd": "${workspaceFolder}",
         "env": {
            "CLX_INFERENCE_PIPELINE": "pytorch",
            "CLX_VOCAB_HASH_FILE": "bert-base-cased-hash.txt",
            "CLX_MODEL_SEQ_LENGTH": "512",
            "CLX_MODEL_MAX_BATCH_SIZE": "18",
         },
         "args": [
            "model",
            "--seq_length",
            "130",
            // "kafka",
            // "--bootstrap_servers=auto",
         ]
      },
      {
         "name": "Python: Onnx-To-TRT",
         "type": "python",
         "request": "launch",
         "program": "${workspaceFolder}/cli_click.py",
         "console": "integratedTerminal",
         "justMyCode": false,
         "cwd": "${workspaceFolder}",
         "env": {
            "CLX_INFERENCE_PIPELINE": "pytorch",
            "CLX_VOCAB_HASH_FILE": "bert-base-cased-hash.txt",
            "CLX_MODEL_SEQ_LENGTH": "512",
            "CLX_MODEL_MAX_BATCH_SIZE": "18",
         },
         "args": [
            "onnx-to-trt",
            // "--help"
            "--input_model=.tmp/models_onnx/mini_bert_128seq.onnx",
            "--output_model=.tmp/models_onnx/mini_bert_128seq_b1-8_b1-16.engine",
            "--batches",
            "1",
            "8",
            "--batches",
            "1",
            "16",
            "--seq_length=128"
         ]
      },
      {
         "name": "Python: Pipeline via Click",
         "type": "python",
         "request": "launch",
         "program": "${workspaceFolder}/cli.py",
         "console": "integratedTerminal",
         "justMyCode": false,
         "cwd": "${workspaceFolder}",
         "env": {
            "CLX_INFERENCE_PIPELINE": "pytorch",
            "CLX_VOCAB_HASH_FILE": "bert-base-cased-hash.txt",
            "CLX_MODEL_SEQ_LENGTH": "512",
            "CLX_MODEL_MAX_BATCH_SIZE": "16",
         },
         "args": [
            "pipeline",
            "--num_threads=4",
            "--model_max_batch_size=32",
            "--model_seq_length=256",
            // "from-file",
            // "--filename=.tmp/dataset4/pcap_dump_augmented_0delay.json",
            "from-kafka",
            "monitor",
            "--description",
            "Input Message Rate",
            "buffer",
            "deserialize",
            "preprocess",
            "buffer",
            "inf-triton",
            "--model_name=mini_bert_trt",
            "--server_url=localhost:8001",
            "monitor",
            "--description",
            "Inference Rate",
            "--smoothing=0.001",
            "--unit",
            "inf",
            "filter",
            "to-kafka",
            "--output_topic",
            "output_topic"
         ]
      },
      {
         "name": "Python: Run Pytorch",
         "type": "python",
         "request": "launch",
         "program": "${workspaceFolder}/cli.py",
         "console": "integratedTerminal",
         "justMyCode": false,
         "cwd": "${workspaceFolder}",
         "env": {
            "CLX_INFERENCE_PIPELINE": "pytorch",
            "CLX_VOCAB_HASH_FILE": "bert-base-cased-hash.txt",
            "CLX_MODEL_SEQ_LENGTH": "256",
            "CLX_MODEL_MAX_BATCH_SIZE": "64",
         },
         "args": []
      },
      {
         "name": "Python: Run Triton (TRT)",
         "type": "python",
         "request": "launch",
         "program": "${workspaceFolder}/cli.py",
         "console": "integratedTerminal",
         "justMyCode": false,
         "cwd": "${workspaceFolder}",
         "env": {
            "CLX_INFERENCE_PIPELINE": "triton",
            "CLX_VOCAB_HASH_FILE": "bert-base-cased-hash.txt",
            "CLX_MODEL_SEQ_LENGTH": "128",
            "CLX_MODEL_MAX_BATCH_SIZE": "32",
            // "PYTHONASYNCIODEBUG": "1",
         },
         "args": []
      },
      {
         "name": "Python: Run Triton (ONNX)",
         "type": "python",
         "request": "launch",
         "program": "${workspaceFolder}/cli.py",
         "console": "integratedTerminal",
         "justMyCode": false,
         "cwd": "${workspaceFolder}",
         "env": {
            "CLX_INFERENCE_PIPELINE": "triton_onnx",
            "CLX_VOCAB_HASH_FILE": "bert-base-cased-hash.txt",
            "CLX_MODEL_SEQ_LENGTH": "128",
            "CLX_MODEL_MAX_BATCH_SIZE": "32",
            // "PYTHONASYNCIODEBUG": "1",
         },
         "args": []
      },
      {
         "name": "Python: Run TensorRT",
         "type": "python",
         "request": "launch",
         "program": "${workspaceFolder}/cli.py",
         "console": "integratedTerminal",
         "justMyCode": false,
         "cwd": "${workspaceFolder}",
         "env": {
            "CLX_INFERENCE_PIPELINE": "tensorrt",
            "CLX_VOCAB_HASH_FILE": "bert-base-cased-hash.txt",
            "CLX_MODEL_SEQ_LENGTH": "128",
            "CLX_MODEL_MAX_BATCH_SIZE": "32",
         },
         "args": []
      },
      {
         "name": "Python: Run Preprocessing",
         "type": "python",
         "request": "launch",
         "program": "${workspaceFolder}/cli.py",
         "console": "integratedTerminal",
         "justMyCode": false,
         "cwd": "${workspaceFolder}",
         "env": {
            "CLX_INFERENCE_PIPELINE": "pytorch",
            "CLX_VOCAB_HASH_FILE": "bert-base-cased-hash.txt",
            "CLX_MODEL_SEQ_LENGTH": "512",
            "CLX_MODEL_MAX_BATCH_SIZE": "16",
         },
         "args": [
            "preprocessing"
         ]
      },
   ]
}