
version: '3.3'

services:
  mlflow-db:
    restart: always
    image: mysql/mysql-server
    container_name: mlflow-db
    expose:
      - "3306"
    networks:
      - backend
    environment:
      - MYSQL_DATABASE=${MYSQL_DATABASE}
      - MYSQL_USER=${MYSQL_USER}
      - MYSQL_PASSWORD=${MYSQL_PASSWORD}
      - MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}
      - MYSQL_ROOT_HOST=${MYSQL_ROOT_HOST}
    volumes:
      - db_data:/var/lib/mysql

  mlflow:
    restart: always
    build: ./mlflow
    image: mlflow_server
    container_name: mlflow_server
    ports:
      - "5000:5000"
    networks:
      - backend
      - frontend
    # environment:
    #   - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
    #   - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
    #   - AWS_DEFAULT_REGION=${AWS_DEFAULT_REGION}
    #command: mlflow server --backend-store-uri mysql+pymysql://${MYSQL_USER}:${MYSQL_PASSWORD}@mlflow-db:3306/${MYSQL_DATABASE} --serve-artifacts --artifacts-destination /opt/mlflow/artifacts --host 0.0.0.0
    #command: mlflow server --backend-store-uri postgresql://mlflow_user:mlflow@localhost/mlflow_db --serve-artifacts --artifacts-destination /opt/mlflow/artifacts --host 0.0.0.0
    command: mlflow server --gunicorn-opts "--log-level debug" --backend-store-uri sqlite:////opt/mlflow/dbdata/mlflow.db --serve-artifacts --artifacts-destination /opt/mlflow/artifacts --host 0.0.0.0
    #command: mlflow server -w 64 --backend-store-uri /opt/mlflow/dstore --serve-artifacts --artifacts-destination /opt/mlflow/artifacts --host 0.0.0.0
    volumes:
      - db_data:/opt/mlflow/dbdata
      - mlflow_data:/opt/mlflow/artifacts
    # depends_on:
    #  - mlflow-db

  jupyter:
    restart: always
    build:
      context: ./morpheus_jupyter
      args:
        - MORPHEUS_CONTAINER_VERSION=v22.08.00a-runtime
    image: dfp_morpheus_jupyter
    container_name: jupyter
    ports:
      - "8888:8888"
    networks:
      - frontend
      - backend
    environment:
      - VAULT_ROLE_ID=${VAULT_ROLE_ID}
      - VAULT_SECRET_ID=${VAULT_SECRET_ID}
    command: jupyter-lab --no-browser --allow-root --ip='*'
    volumes:
      - ../..:/work
    working_dir: /work/examples/dfp_workflow
    depends_on:
      - mlflow
    profiles:
      - dev

  morpheus_training:
    # restart: always
    build:
      context: ./morpheus
      args:
        - MORPHEUS_CONTAINER_VERSION=v22.08.00a-runtime
    image: dfp_morpheus
    container_name: morpheus_training
    networks:
      - frontend
      - backend
    environment:
      # Colorize the terminal in the container if possible
      TERM: "${TERM:-}"
      # PS1: "$$(whoami):$$(pwd) $$ "
      VAULT_ROLE_ID: "${VAULT_ROLE_ID}"
      VAULT_SECRET_ID: "${VAULT_SECRET_ID}"
      VAULT_ADDR: "${VAULT_ADDR}"
      VAULT_NAMESPACE:  heimdall
      VAULT_SECRET_PATH: aws/heimdall/sts/heimdall-deployments
      VAULT_LOGIN_PATH: auth/heimdall-deployments/login
      VAULT_TOKEN: "${VAULT_TOKEN}"
      AWS_CREDENTIALS: "${AWS_CREDENTIALS}"
      AWS_ACCESS_KEY_ID: "${AWS_ACCESS_KEY_ID}"
      AWS_SECRET_ACCESS_KEY: "${AWS_SECRET_ACCESS_KEY}"
      AWS_SESSION_TOKEN: "${AWS_SESSION_TOKEN}"
      NGC_CLI_API_KEY:  "${NGC_CLI_API_KEY}"
      DFP_CACHE_DIR: "/work/.cache/dfp"
      DFP_TRACKING_URI: "http://mlflow:5000"
    command: ./launch.sh --train_users=generic --duration=1d
    volumes:
      # - ./.s3_cache:/work/.s3_cache
      - ../..:/work
      # - /etc/passwd:/etc/passwd:ro
      # - /etc/group:/etc/group:ro
    working_dir: /work/examples/dfp_workflow/morpheus
    depends_on:
      - mlflow
    profiles:
      - training
    cap_add:
      - sys_nice
    user: "${UID}:${GID}"

  # nginx:
  #   restart: always
  #   build: ./nginx
  #   image: mlflow_nginx
  #   container_name: mlflow_nginx
  #   ports:
  #     - "80:80"
  #   networks:
  #     - frontend
  #   depends_on:
  #     - web

networks:
  frontend:
    driver: bridge
  backend:
    driver: bridge

volumes:
  db_data:
  mlflow_data:
