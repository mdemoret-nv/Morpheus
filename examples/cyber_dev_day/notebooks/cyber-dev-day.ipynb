{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2941e94f-db20-44a5-ab87-2cab499825f7",
   "metadata": {},
   "source": [
    "# Cyber Developer Day 2024\n",
    "## Introduction\n",
    "\n",
    "TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4700a3a1",
   "metadata": {},
   "source": [
    "### Environment Setup\n",
    "\n",
    "The following code blocks are used to setup environment variables and imports for the rest of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a60d2a30",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%aimport -logging\n",
    "%autoreload 2\n",
    "\n",
    "# Ensure that the morpheus directory is in the python path. This may not need to be run depending on the environment setup\n",
    "import sys\n",
    "import os\n",
    "\n",
    "if (\"MORPHEUS_ROOT\" not in os.environ):\n",
    "    os.environ[\"MORPHEUS_ROOT\"] = os.path.abspath(\"../../..\")\n",
    "\n",
    "llm_dir = os.path.abspath(os.path.join(os.getenv(\"MORPHEUS_ROOT\", \"../../..\"), \"examples\", \"cyber_dev_day\"))\n",
    "\n",
    "if (llm_dir not in sys.path):\n",
    "    sys.path.append(llm_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3523bc32",
   "metadata": {},
   "source": [
    "Ensure the necessary environment variables are set. As a last resort, try to load them from a `.env` file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef295094",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure that the current environment is set up with API keys\n",
    "required_env_vars = [\n",
    "    \"MORPHEUS_ROOT\",\n",
    "    \"NGC_API_KEY\",\n",
    "    \"NVIDIA_API_KEY\",\n",
    "]\n",
    "\n",
    "if (not all([var in os.environ for var in required_env_vars])):\n",
    "\n",
    "    # Try loading an .env file if it exists\n",
    "    from dotenv import load_dotenv\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    # Check again\n",
    "    if (not all([var in os.environ for var in required_env_vars])):\n",
    "        raise ValueError(f\"Please set the following environment variables: {required_env_vars}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2aa2691",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Global imports\n",
    "import os\n",
    "import sys\n",
    "import cudf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7932f728",
   "metadata": {},
   "source": [
    "Configure logging to allow Morpheus messages to appear in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9ab76ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "import logging\n",
    "import cyber_dev_day\n",
    "\n",
    "# Create a logger for this module. Use the cyber_dev_day module name because the notebook will just be __main__\n",
    "logger = logging.getLogger(cyber_dev_day.__name__)\n",
    "\n",
    "# Configure the root logger log level\n",
    "logger.root.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78a1fcfd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully configured logging!\n"
     ]
    }
   ],
   "source": [
    "# Test the logger out. You should see the log message in the output\n",
    "logger.info(\"Successfully configured logging!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb62b83",
   "metadata": {},
   "source": [
    "## Part 1 - Intro to Interacting with LLMs\n",
    "\n",
    "This section will go over how to integrate LLMs into code with GUI or Python based examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8634848",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Request succeeded with HTTP Status Code 200 OK Full response: {\"text\":\" Hey Mason,  I think we should compete in the next week's football tournament. I think it would be fun and the winner will get $100. I think you are a good player and I am sure you will win. I will be waiting for your response.  From,  John.\",\"cumlogprobs\":-46.16297,\"prompt_labels\":[{\"class_name\":\"nontoxic\",\"score\":0.99038994}],\"completion_labels\":[{\"class_name\":\"nontoxic\",\"score\":0.9922271}]}\n",
      "\n",
      "{'completion_labels': [{'class_name': 'nontoxic', 'score': 0.9922271}],\n",
      " 'cumlogprobs': -46.16297,\n",
      " 'prompt_labels': [{'class_name': 'nontoxic', 'score': 0.99038994}],\n",
      " 'text': \" Hey Mason,  I think we should compete in the next week's football \"\n",
      "         'tournament. I think it would be fun and the winner will get $100. I '\n",
      "         'think you are a good player and I am sure you will win. I will be '\n",
      "         'waiting for your response.  From,  John.'}\n"
     ]
    }
   ],
   "source": [
    "from nemollm.api import NemoLLM\n",
    "from pprint import pprint\n",
    "\n",
    "# If you do not specify an api_key or an org_id, it will use environment variables\n",
    "conn = NemoLLM()\n",
    "\n",
    "response = conn.generate(\n",
    "  prompt=\"Message Mason saying that we should compete in next week's football tournament, and tell him that the winner will get $100.\",\n",
    "  model=\"gpt-43b-002\",\n",
    "  customization_id=\"f4cd7435-def4-41e5-835b-9febb679ce01\",\n",
    "  stop=[],\n",
    "  tokens_to_generate=150,\n",
    "  temperature=1.0,\n",
    "  top_k=1,\n",
    "  top_p=0.0,\n",
    "  random_seed=0,\n",
    "  beam_search_diversity_rate=0.0,\n",
    "  beam_width=1,\n",
    "  repetition_penalty=1.0,\n",
    "  length_penalty=1.0,\n",
    ")\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6b528a",
   "metadata": {},
   "source": [
    "Try some for yourself! Here are a few other ideas on things to try out: \n",
    "\n",
    "1. Try out different prompts and see how the model responds\n",
    "   1. Are there prompts that work better than others?\n",
    "2. Try out different models and see how they compare\n",
    "   1. Are there models that work better than others?\n",
    "   2. You can use any one of these models: `[\"gpt-8b-000\", \"gpt-20b\", \"gpt-43b-002\"]`\n",
    "3. Try out different temperature values and see how they compare\n",
    "   1. Are there temperature values that work better than others?\n",
    "   2. What happens when you set the temperature to 0? What about 1?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afdc87a",
   "metadata": {},
   "source": [
    "## Part 2 - Prototyping\n",
    "\n",
    "Building a Pipeline with LLMs to Analyze CVEs\n",
    "\n",
    "### Overview\n",
    "\n",
    "Background of RAG, data sources, building vector databases\n",
    "\n",
    "### Building the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0c5175d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "Generating embedding for source code in /workspace\n",
      "Total 1028 source code documents in 623 files.\n",
      "Creating embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79b0c2f719e248ee88cefe335cd5de25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/166 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading faiss with AVX2 support.\n",
      "Successfully loaded faiss with AVX2 support.\n",
      "Creating embeddings... Complete\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.huggingface import HuggingFaceEmbeddings\n",
    "from cyber_dev_day.embeddings import create_code_embedding\n",
    "\n",
    "# Create the embedding object that will be used to generate the embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\", model_kwargs={\"device\":\"cuda\"}, show_progress=True)\n",
    "\n",
    "# Create a vector database of the code using the supplied embedding function. The returned value will be a\n",
    "# FaissVectorDatabase object.\n",
    "# NOTE: This may take a few minutes to run.\n",
    "faiss_vdb = create_code_embedding(code_dir=os.getenv(\"MORPHEUS_ROOT\"), embedding=embeddings, include_notebooks=False, exclude=[\n",
    "    \".cache/**/*.py\",\n",
    "    \"build*/**/*.py\"\n",
    "])\n",
    "\n",
    "# Save the vector database to disk\n",
    "code_faiss_dir = os.path.join(os.getenv(\"MORPHEUS_ROOT\"), \".tmp\", \"morpheus_code_faiss\")\n",
    "\n",
    "faiss_vdb.save_local(code_faiss_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0cd628",
   "metadata": {},
   "source": [
    "### Running a RAG Pipeline with Morpheus\n",
    "\n",
    "How do we utilize the Vector Database to answer questions?\n",
    "\n",
    "#### Morpheus Overview\n",
    "\n",
    "Quick overview of what Morpheus is and how to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec9cbc52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from morpheus.config import Config, PipelineModes\n",
    "\n",
    "# Create the pipeline config\n",
    "pipeline_config = Config()\n",
    "pipeline_config.mode = PipelineModes.OTHER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7829100",
   "metadata": {},
   "source": [
    "#### Building a Morpheus RAG Pipeline\n",
    "\n",
    "Below, we will build a pipeline that uses Morpheus to answer questions about the code in the repository that we created a vector database for. This works by using the `LLMEngine` in Morpheus with a `RAGNode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3833deda",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/morpheus/lib/python3.10/site-packages/pydantic/_internal/_fields.py:151: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from textwrap import dedent\n",
    "import cudf\n",
    "from cyber_dev_day.config import EngineConfig, LLMModelConfig, NVFoundationLLMModelConfig\n",
    "from morpheus._lib.llm import LLMEngine\n",
    "from morpheus.llm.nodes.extracter_node import ExtracterNode\n",
    "from morpheus.llm.nodes.rag_node import RAGNode\n",
    "from morpheus.llm.services.llm_service import LLMService\n",
    "from morpheus.llm.task_handlers.simple_task_handler import SimpleTaskHandler\n",
    "from morpheus.messages import ControlMessage\n",
    "\n",
    "from morpheus.pipeline.linear_pipeline import LinearPipeline\n",
    "from morpheus.service.vdb.faiss_vdb_service import FaissVectorDBService\n",
    "from morpheus.stages.input.in_memory_source_stage import InMemorySourceStage\n",
    "from morpheus.stages.llm.llm_engine_stage import LLMEngineStage\n",
    "from morpheus.stages.output.in_memory_sink_stage import InMemorySinkStage\n",
    "from morpheus.stages.preprocess.deserialize_stage import DeserializeStage\n",
    "from morpheus.utils.concat_df import concat_dataframes\n",
    "\n",
    "def _build_rag_llm_engine(model_config: LLMModelConfig):\n",
    "\n",
    "    engine = LLMEngine()\n",
    "\n",
    "    engine.add_node(\"extracter\", node=ExtracterNode())\n",
    "\n",
    "    prompt = dedent(\"\"\"\n",
    "    You are a helpful assistant. Given the following background information:\n",
    "    {% for c in contexts -%}\n",
    "    Source File: {{ c.metadata.source }}\n",
    "    Source File Language: {{ c.metadata.language }}\n",
    "    Source Content:\n",
    "    ```\n",
    "    {{ c.page_content }}\n",
    "    ```\n",
    "    {% endfor %}\n",
    "\n",
    "    Please answer the following question:\n",
    "    {{ query }}\n",
    "    \"\"\").strip(\"\\n\")\n",
    "\n",
    "    vector_service = FaissVectorDBService(code_faiss_dir, embeddings=embeddings)\n",
    "\n",
    "    vdb_resource = vector_service.load_resource()\n",
    "\n",
    "    llm_service = LLMService.create(model_config.service.type, **model_config.service.model_dump(exclude={\"type\"}))\n",
    "\n",
    "    llm_client = llm_service.get_client(**model_config.model_dump(exclude={\"service\"}))\n",
    "\n",
    "    # Async wrapper around embeddings\n",
    "    async def calc_embeddings(texts: list[str]) -> list[list[float]]:\n",
    "        return embeddings.embed_documents(texts)\n",
    "\n",
    "    engine.add_node(\"rag\",\n",
    "                    inputs=[\"/extracter\"],\n",
    "                    node=RAGNode(prompt=prompt,\n",
    "                                 vdb_service=vdb_resource,\n",
    "                                 embedding=calc_embeddings,\n",
    "                                 llm_client=llm_client))\n",
    "\n",
    "    engine.add_task_handler(inputs=[\"/rag\"], handler=SimpleTaskHandler())\n",
    "\n",
    "    return engine\n",
    "\n",
    "async def run_rag_pipeline(p_config: Config, model_config: LLMModelConfig, question: str):\n",
    "    source_dfs = [\n",
    "        cudf.DataFrame({\"questions\": [question]}),\n",
    "    ]\n",
    "\n",
    "    completion_task = {\"task_type\": \"completion\", \"task_dict\": {\"input_keys\": [\"questions\"], }}\n",
    "\n",
    "    pipe = LinearPipeline(p_config)\n",
    "\n",
    "    pipe.set_source(InMemorySourceStage(p_config, dataframes=source_dfs))\n",
    "\n",
    "    pipe.add_stage(\n",
    "        DeserializeStage(p_config, message_type=ControlMessage, task_type=\"llm_engine\", task_payload=completion_task))\n",
    "\n",
    "    pipe.add_stage(\n",
    "        LLMEngineStage(p_config,\n",
    "                        engine=_build_rag_llm_engine(model_config)))\n",
    "\n",
    "    sink = pipe.add_stage(InMemorySinkStage(p_config))\n",
    "\n",
    "    await pipe.run_async()\n",
    "\n",
    "    messages = sink.get_messages()\n",
    "    responses = concat_dataframes(messages)\n",
    "\n",
    "    # The responses are quite long, when debug is enabled disable the truncation that pandas and cudf normally\n",
    "    # perform on the output\n",
    "    pd.set_option('display.max_colwidth', None)\n",
    "    print(\"Response:\\n%s\" % (responses['response'].iloc[0], ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd9f1092",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Pipeline Pre-build====\n",
      "====Pre-Building Segment: linear_segment_0====\n",
      "====Pre-Building Segment Complete!====\n",
      "====Pipeline Pre-build Complete!====\n",
      "====Registering Pipeline====\n",
      "====Building Pipeline====\n",
      "====Building Pipeline Complete!====\n",
      "====Registering Pipeline Complete!====\n",
      "====Starting Pipeline====\n",
      "====Pipeline Started====\n",
      "====Building Segment: linear_segment_0====\n",
      "Added source: <from-mem-0; InMemorySourceStage(dataframes=[                                           questions\n",
      "0  Does the code repo import the `pyarrow_hotfix`...], repeat=1)>\n",
      "  └─> morpheus.MessageMeta\n",
      "Added stage: <deserialize-1; DeserializeStage(ensure_sliceable_index=True, message_type=<class 'morpheus._lib.messages.ControlMessage'>, task_type=llm_engine, task_payload={'task_type': 'completion', 'task_dict': {'input_keys': ['questions']}})>\n",
      "  └─ morpheus.MessageMeta -> morpheus.ControlMessage\n",
      "Added stage: <llm-engine-2; LLMEngineStage(engine=<morpheus._lib.llm.LLMEngine object at 0x7f3bdc111d70>)>\n",
      "  └─ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "Added stage: <to-mem-3; InMemorySinkStage()>\n",
      "  └─ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "====Building Segment Complete!====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogleLogging() is written to STDERR\n",
      "I20240311 03:39:36.869108  6834 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240311 03:39:36.869587  6834 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a805db62a8d54773b72e86e968ad28c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Pipeline Complete====\n",
      "Response:\n",
      "Yes, the `pyarrow_hotfix` package is imported in the `/workspace/morpheus/__init__.py` file, which is the root package of the Morpheus library. The import statement `import pyarrow_hotfix` can be found near the end of the file.\n"
     ]
    }
   ],
   "source": [
    "model_config = NVFoundationLLMModelConfig.model_validate({\n",
    "    \"service\": {\n",
    "        \"type\": \"nvfoundation\", \"api_key\": None\n",
    "    },\n",
    "    \"model_name\": \"mixtral_8x7b\",\n",
    "    \"temperature\": 0.0\n",
    "})\n",
    "\n",
    "# Run the Pipeline\n",
    "await run_rag_pipeline(pipeline_config, model_config, \"Does the code repo import the `pyarrow_hotfix` package from the `morpheus` root package?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0380153a",
   "metadata": {},
   "source": [
    "### RAG Limitations\n",
    "\n",
    "Using the pipeline we built, we can now ask questions about the code in the repository and the LLM will be able use the vector database to answer them. However, what happens if we need to ask questions about the code that are not in the vector database? For example, what if we needed to ask questions about the dependencies that the code uses? Would the LLM be able to answer these questions? Let's try it out by re-running our RAG pipeline with a more complex question:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "506b5fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Pipeline Pre-build====\n",
      "====Pre-Building Segment: linear_segment_0====\n",
      "====Pre-Building Segment Complete!====\n",
      "====Pipeline Pre-build Complete!====\n",
      "====Registering Pipeline====\n",
      "====Building Pipeline====\n",
      "====Building Pipeline Complete!====\n",
      "====Registering Pipeline Complete!====\n",
      "====Starting Pipeline====\n",
      "====Building Segment: linear_segment_0====\n",
      "====Pipeline Started====\n",
      "Added source: <from-mem-4; InMemorySourceStage(dataframes=[                                                            questions\n",
      "0  Does the code repo use `langchain` functions which are deprecated?], repeat=1)>\n",
      "  └─> morpheus.MessageMeta\n",
      "Added stage: <deserialize-5; DeserializeStage(ensure_sliceable_index=True, message_type=<class 'morpheus._lib.messages.ControlMessage'>, task_type=llm_engine, task_payload={'task_type': 'completion', 'task_dict': {'input_keys': ['questions']}})>\n",
      "  └─ morpheus.MessageMeta -> morpheus.ControlMessage\n",
      "Added stage: <llm-engine-6; LLMEngineStage(engine=<morpheus._lib.llm.LLMEngine object at 0x7f39897d3930>)>\n",
      "  └─ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "Added stage: <to-mem-7; InMemorySinkStage()>\n",
      "  └─ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "====Building Segment Complete!====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240311 03:39:37.368492  6841 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240311 03:39:37.375123  6841 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "381284167644482fade15e837463a2d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Pipeline Complete====\n",
      "Response:\n",
      "Based on the provided source files, I cannot determine if the code repo uses `langchain` functions that are deprecated. The `langchain_fixture` function in the `/workspace/tests/examples/llm/common/conftest.py` file only checks if `langchain` is installed and imports it if it is. It does not use any specific functions or methods from the `langchain` package.\n",
      "\n",
      "To determine if `langchain` functions are being used and if they are deprecated, you would need to examine the other source files in the code repo where `langchain` is imported and used. You can check the documentation for the version of `langchain` being used to see if any of the functions or methods being used are deprecated.\n"
     ]
    }
   ],
   "source": [
    "# Run the Pipeline\n",
    "await run_rag_pipeline(pipeline_config, model_config, \"Does the code repo use `langchain` functions which are deprecated?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abd8482",
   "metadata": {},
   "source": [
    "It's likely that the model was not able to determine the answer to this question because it would need additional information. Depending on the model used, you might see output similar to:\n",
    "```\n",
    "Based on the provided source code, I cannot determine if the `langchain` functions used in the code are deprecated or not.\n",
    "\n",
    "To determine if `langchain` functions are deprecated, you would need to check the documentation for the specific functions being used in the code or consult the maintainers of the `langchain` package.\n",
    "```\n",
    "\n",
    "How would we go about solving this problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d28e86",
   "metadata": {},
   "source": [
    "#### Answering Complex Question with RAG + LLM Agents\n",
    "\n",
    "Intro to LLM Agents and how our checklist + agents approach can help solve multi-step problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b81070",
   "metadata": {},
   "source": [
    "### Running the CVE Pipeline with Morpheus\n",
    "\n",
    "#### The Engine Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b628e418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from cyber_dev_day.config import EngineConfig\n",
    "\n",
    "# Create the engine configuration\n",
    "engine_config = EngineConfig.model_validate({\n",
    "    'checklist': {\n",
    "        'model': {\n",
    "            'service': {\n",
    "                'type': 'nemo', 'api_key': None, 'org_id': None\n",
    "            },\n",
    "            'model_name': 'gpt-43b-002',\n",
    "            'customization_id': None,\n",
    "            'temperature': 0.0,\n",
    "            'tokens_to_generate': 300\n",
    "        }\n",
    "    },\n",
    "    'agent': {\n",
    "        'model': {\n",
    "            'service': {\n",
    "                'type': 'nvfoundation', 'api_key': None\n",
    "            }, 'model_name': 'mixtral_8x7b', 'temperature': 0.0\n",
    "        },\n",
    "        'sbom': {\n",
    "            'data_file': ''\n",
    "        },\n",
    "        'code_repo': {\n",
    "            'faiss_dir': code_faiss_dir,\n",
    "            'embedding_model_name': \"sentence-transformers/all-mpnet-base-v2\"\n",
    "        }\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09f759e4-fc8c-4c84-ba15-3f3408a2bff3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"checklist\": {\n",
      "    \"model\": {\n",
      "      \"service\": {\n",
      "        \"type\": \"nemo\",\n",
      "        \"api_key\": null,\n",
      "        \"org_id\": null\n",
      "      },\n",
      "      \"model_name\": \"gpt-43b-002\",\n",
      "      \"customization_id\": null,\n",
      "      \"temperature\": 0.0,\n",
      "      \"tokens_to_generate\": 300\n",
      "    }\n",
      "  },\n",
      "  \"agent\": {\n",
      "    \"model\": {\n",
      "      \"service\": {\n",
      "        \"type\": \"nvfoundation\",\n",
      "        \"api_key\": null\n",
      "      },\n",
      "      \"model_name\": \"mixtral_8x7b\",\n",
      "      \"temperature\": 0.0\n",
      "    },\n",
      "    \"sbom\": {\n",
      "      \"data_file\": \"\"\n",
      "    },\n",
      "    \"code_repo\": {\n",
      "      \"faiss_dir\": \"/workspace/.tmp/morpheus_code_faiss\",\n",
      "      \"embedding_model_name\": \"sentence-transformers/all-mpnet-base-v2\"\n",
      "    }\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Print the current configuration object\n",
    "print(engine_config.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98b0bf2",
   "metadata": {},
   "source": [
    "#### The Pipeline Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a16bf979",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import cudf\n",
    "from cyber_dev_day.pipeline_utils import build_cve_llm_engine\n",
    "from morpheus.messages import ControlMessage\n",
    "from morpheus.pipeline.linear_pipeline import LinearPipeline\n",
    "from morpheus.stages.input.in_memory_source_stage import InMemorySourceStage\n",
    "from morpheus.stages.llm.llm_engine_stage import LLMEngineStage\n",
    "from morpheus.stages.output.in_memory_sink_stage import InMemorySinkStage\n",
    "from morpheus.stages.preprocess.deserialize_stage import DeserializeStage\n",
    "from morpheus.utils.concat_df import concat_dataframes\n",
    "\n",
    "async def run_cve_pipeline(p_config: Config, e_config: EngineConfig, input_cves: list[str]):\n",
    "    source_dfs = [\n",
    "        cudf.DataFrame({\n",
    "            \"cve_info\": input_cves\n",
    "        })\n",
    "    ]\n",
    "\n",
    "    completion_task = {\"task_type\": \"completion\", \"task_dict\": {\"input_keys\": [\"cve_info\"], }}\n",
    "\n",
    "    pipe = LinearPipeline(p_config)\n",
    "\n",
    "    pipe.set_source(InMemorySourceStage(p_config, dataframes=source_dfs))\n",
    "\n",
    "    pipe.add_stage(DeserializeStage(p_config, message_type=ControlMessage, task_type=\"llm_engine\", task_payload=completion_task))\n",
    "\n",
    "    pipe.add_stage(LLMEngineStage(p_config, engine=build_cve_llm_engine(e_config)))\n",
    "\n",
    "    sink = pipe.add_stage(InMemorySinkStage(p_config))\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    await pipe.run_async()\n",
    "\n",
    "    messages = sink.get_messages()\n",
    "    responses = concat_dataframes(messages)\n",
    "\n",
    "    logger.info(\"Pipeline complete\")\n",
    "\n",
    "    print(\"Pipeline complete. Received %s responses:\\n%s\" % (len(messages), responses['response']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "001ee70c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "====Pipeline Pre-build====\n",
      "====Pre-Building Segment: linear_segment_0====\n",
      "====Pre-Building Segment Complete!====\n",
      "====Pipeline Pre-build Complete!====\n",
      "====Registering Pipeline====\n",
      "====Building Pipeline====\n",
      "====Building Pipeline Complete!====\n",
      "====Registering Pipeline Complete!====\n",
      "====Starting Pipeline====\n",
      "====Pipeline Started====\n",
      "====Building Segment: linear_segment_0====\n",
      "Added source: <from-mem-8; InMemorySourceStage(dataframes=[                                                                                                                                                                       cve_info\n",
      "0  An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.], repeat=1)>\n",
      "  └─> morpheus.MessageMeta\n",
      "Added stage: <deserialize-9; DeserializeStage(ensure_sliceable_index=True, message_type=<class 'morpheus._lib.messages.ControlMessage'>, task_type=llm_engine, task_payload={'task_type': 'completion', 'task_dict': {'input_keys': ['cve_info']}})>\n",
      "  └─ morpheus.MessageMeta -> morpheus.ControlMessage\n",
      "Added stage: <llm-engine-10; LLMEngineStage(engine=<morpheus._lib.llm.LLMEngine object at 0x7f39896127f0>)>\n",
      "  └─ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "Added stage: <to-mem-11; InMemorySinkStage()>\n",
      "  └─ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "====Building Segment Complete!====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/morpheus/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n",
      "I20240311 03:39:42.666868  6850 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240311 03:39:42.680075  6850 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n",
      "/opt/conda/envs/morpheus/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `arun` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use ainvoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel version is affected by this issue and if the vulnerable file is present in the container.\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFalse\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe SBOM Package Checker returned False, which means the Linux kernel is not present in the Docker container's software bill of materials. Therefore, I cannot determine if the container's Linux kernel version is affected by the issue. However, I can still check if the vulnerable file is present in the container.\n",
      "\n",
      "Action: Docker Container Code QA System\n",
      "Action Input: drivers/media/dvb-core/dvbdev.c\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe string \"drivers/media/dvb-core/dvbdev.c\" appears to be a part of a CVE (Common Vulnerabilities and Exposures) information, specifically a use-after-free vulnerability found in the Linux kernel through version 6.0.9. This issue is related to the `dvb_register_device` function that dynamically allocates fops.\n",
      "\n",
      "The text seems to be a part of a dataframe in the source_dfs list, which is used as input for a pipeline in the given code snippet. It is not directly related to the copyrights, licenses, or the configuration of the pipeline.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "====Pipeline Complete====\n",
      "Pipeline complete\n",
      "Pipeline complete. Received 1 responses:\n",
      "\"\"\n",
      "0    Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\n",
      "Name: response, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Now run the pipeline with a specified CVE description\n",
    "await run_cve_pipeline(pipeline_config, engine_config, [\n",
    "    \"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4b8a57",
   "metadata": {},
   "source": [
    "### Hitting the Limits of the LLMs\n",
    "\n",
    "This section will go over some of the areas where LLMs may fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a7e791c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example to cause the LLM to fail (TBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8c30da",
   "metadata": {},
   "source": [
    "## Part 3 - Beyond Prototyping\n",
    "\n",
    "This section will focus on refining the prototype to fix any gaps, improve the accuracy, and create a production ready pipeline.\n",
    "\n",
    "### Improving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f91ef4fe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "====Pipeline Pre-build====\n",
      "====Pre-Building Segment: linear_segment_0====\n",
      "====Pre-Building Segment Complete!====\n",
      "====Pipeline Pre-build Complete!====\n",
      "====Registering Pipeline====\n",
      "====Building Pipeline====\n",
      "====Building Pipeline Complete!====\n",
      "====Registering Pipeline Complete!====\n",
      "====Starting Pipeline====\n",
      "====Pipeline Started====\n",
      "====Building Segment: linear_segment_0====\n",
      "Added source: <from-mem-12; InMemorySourceStage(dataframes=[                                                                                                                                                                       cve_info\n",
      "0  An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.], repeat=1)>\n",
      "  └─> morpheus.MessageMeta\n",
      "Added stage: <deserialize-13; DeserializeStage(ensure_sliceable_index=True, message_type=<class 'morpheus._lib.messages.ControlMessage'>, task_type=llm_engine, task_payload={'task_type': 'completion', 'task_dict': {'input_keys': ['cve_info']}})>\n",
      "  └─ morpheus.MessageMeta -> morpheus.ControlMessage\n",
      "Added stage: <llm-engine-14; LLMEngineStage(engine=<morpheus._lib.llm.LLMEngine object at 0x7f3958de6330>)>\n",
      "  └─ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "Added stage: <to-mem-15; InMemorySinkStage()>\n",
      "  └─ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "====Building Segment Complete!====\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240311 03:39:46.376272  6858 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240311 03:39:46.377018  6858 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel version is affected by this issue and if the vulnerable file is present in the container.\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFalse\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe SBOM Package Checker returned False, which means the Linux kernel is not present in the Docker container's software bill of materials. Therefore, I cannot determine if the container's Linux kernel version is affected by the issue. However, I can still check if the vulnerable file is present in the container.\n",
      "\n",
      "Action: Docker Container Code QA System\n",
      "Action Input: drivers/media/dvb-core/dvbdev.c\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe string \"drivers/media/dvb-core/dvbdev.c\" appears to be a part of a CVE (Common Vulnerabilities and Exposures) information, specifically a use-after-free vulnerability found in the Linux kernel through version 6.0.9. This issue is related to the `dvb_register_device` function that dynamically allocates fops.\n",
      "\n",
      "The text seems to be a part of a dataframe in the source_dfs list, which is used as input for a pipeline in the given code snippet. It is not directly related to the copyrights, licenses, or the configuration of the pipeline.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "====Pipeline Complete====\n",
      "Pipeline complete\n",
      "Pipeline complete. Received 1 responses:\n",
      "\"\"\n",
      "0    Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\n",
      "Name: response, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Code for improving the model\n",
    "engine_config_custom_model = engine_config.model_copy(deep=True)\n",
    "\n",
    "# Set the customization ID\n",
    "# engine_config_custom_model.checklist.model.customization_id = \"<CUSTOMIZATION_ID>\"\n",
    "\n",
    "# Run the pipeline\n",
    "await run_cve_pipeline(pipeline_config, engine_config_custom_model, [\n",
    "    \"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a826b5",
   "metadata": {},
   "source": [
    "### Batching Multiple Requests\n",
    "\n",
    "This section will show how to run multiple requests simultaneously improving the throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "895f9bcf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "====Pipeline Pre-build====\n",
      "====Pre-Building Segment: linear_segment_0====\n",
      "====Pre-Building Segment Complete!====\n",
      "====Pipeline Pre-build Complete!====\n",
      "====Registering Pipeline====\n",
      "====Building Pipeline====\n",
      "====Building Pipeline Complete!====\n",
      "====Registering Pipeline Complete!====\n",
      "====Starting Pipeline====\n",
      "====Pipeline Started====\n",
      "====Building Segment: linear_segment_0====\n",
      "Added source: <from-mem-16; InMemorySourceStage(dataframes=[                                                                                                                                                                       cve_info\n",
      "0  An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\n",
      "1  An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\n",
      "2  An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\n",
      "3  An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\n",
      "4  An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.], repeat=1)>\n",
      "  └─> morpheus.MessageMeta\n",
      "Added stage: <deserialize-17; DeserializeStage(ensure_sliceable_index=True, message_type=<class 'morpheus._lib.messages.ControlMessage'>, task_type=llm_engine, task_payload={'task_type': 'completion', 'task_dict': {'input_keys': ['cve_info']}})>\n",
      "  └─ morpheus.MessageMeta -> morpheus.ControlMessage\n",
      "Added stage: <llm-engine-18; LLMEngineStage(engine=<morpheus._lib.llm.LLMEngine object at 0x7f3958631fb0>)>\n",
      "  └─ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "Added stage: <to-mem-19; InMemorySinkStage()>\n",
      "  └─ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "====Building Segment Complete!====\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240311 03:39:50.082346  6867 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240311 03:39:50.083042  6867 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel version is affected by this issue and if the vulnerable file is present in the container.\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFalse\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel version is affected by this issue and if the vulnerable file is present in the container.\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\u001b[0m\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel version is affected by this issue and if the vulnerable file is present in the container.\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\u001b[0m\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel version is affected by this issue and if the vulnerable file is present in the container.\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\u001b[0m\u001b[32;1m\u001b[1;3mThe SBOM Package Checker returned False, which means the Linux kernel is not present in the Docker container's software bill of materials. Therefore, I cannot determine if the container's Linux kernel version is affected by the issue. However, I can still check if the vulnerable file is present in the container.\n",
      "\n",
      "Action: Docker Container Code QA System\n",
      "Action Input: drivers/media/dvb-core/dvbdev.c\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFalse\u001b[0m\n",
      "Thought:\n",
      "Observation: \u001b[36;1m\u001b[1;3mFalse\u001b[0m\n",
      "Thought:\n",
      "Observation: \u001b[36;1m\u001b[1;3mFalse\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel version is affected by this issue and if the vulnerable file is present in the container.\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\u001b[0m\u001b[32;1m\u001b[1;3mThe SBOM Package Checker returned False, which means the Linux kernel is not present in the Docker container's software bill of materials. Therefore, I cannot determine if the container's Linux kernel version is affected by the issue. However, I can still check if the vulnerable file is present in the container.\n",
      "\n",
      "Action: Docker Container Code QA System\n",
      "Action Input: drivers/media/dvb-core/dvbdev.c\u001b[0m\u001b[32;1m\u001b[1;3mThe SBOM Package Checker returned False, which means the Linux kernel is not present in the Docker container's software bill of materials. Therefore, I cannot determine if the container's Linux kernel version is affected by the issue. However, I can still check if the vulnerable file is present in the container.\n",
      "\n",
      "Action: Docker Container Code QA System\n",
      "Action Input: drivers/media/dvb-core/dvbdev.c\u001b[0m\u001b[32;1m\u001b[1;3mThe SBOM Package Checker returned False, which means the Linux kernel is not present in the Docker container's software bill of materials. Therefore, I cannot determine if the container's Linux kernel version is affected by the issue. However, I can still check if the vulnerable file is present in the container.\n",
      "\n",
      "Action: Docker Container Code QA System\n",
      "Action Input: drivers/media/dvb-core/dvbdev.c\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFalse\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe SBOM Package Checker returned False, which means the Linux kernel is not present in the Docker container's software bill of materials. Therefore, I cannot determine if the container's Linux kernel version is affected by the issue. However, I can still check if the vulnerable file is present in the container.\n",
      "\n",
      "Action: Docker Container Code QA System\n",
      "Action Input: drivers/media/dvb-core/dvbdev.c\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe string \"drivers/media/dvb-core/dvbdev.c\" appears to be a part of a CVE (Common Vulnerabilities and Exposures) information, specifically a use-after-free vulnerability found in the Linux kernel through version 6.0.9. This issue is related to the `dvb_register_device` function that dynamically allocates fops.\n",
      "\n",
      "The text seems to be a part of a dataframe in the source_dfs list, which is used as input for a pipeline in the given code snippet. It is not directly related to the copyrights, licenses, or the configuration of the pipeline.\u001b[0m\n",
      "Thought:\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe string \"drivers/media/dvb-core/dvbdev.c\" appears to be a part of a CVE (Common Vulnerabilities and Exposures) information, specifically a use-after-free vulnerability found in the Linux kernel through version 6.0.9. This issue is related to the `dvb_register_device` function that dynamically allocates fops.\n",
      "\n",
      "The text seems to be a part of a dataframe in the source_dfs list, which is used as input for a pipeline in the given code snippet. It is not directly related to the copyrights, licenses, or the configuration of the pipeline.\u001b[0m\n",
      "Thought:\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe string \"drivers/media/dvb-core/dvbdev.c\" appears to be a part of a CVE (Common Vulnerabilities and Exposures) information, specifically a use-after-free vulnerability found in the Linux kernel through version 6.0.9. This issue is related to the `dvb_register_device` function that dynamically allocates fops.\n",
      "\n",
      "The text seems to be a part of a dataframe in the source_dfs list, which is used as input for a pipeline in the given code snippet. It is not directly related to the copyrights, licenses, or the configuration of the pipeline.\u001b[0m\n",
      "Thought:\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe string \"drivers/media/dvb-core/dvbdev.c\" appears to be a part of a CVE (Common Vulnerabilities and Exposures) information, specifically a use-after-free vulnerability found in the Linux kernel through version 6.0.9. This issue is related to the `dvb_register_device` function that dynamically allocates fops.\n",
      "\n",
      "The text seems to be a part of a dataframe in the source_dfs list, which is used as input for a pipeline in the given code snippet. It is not directly related to the copyrights, licenses, or the configuration of the pipeline.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe string \"drivers/media/dvb-core/dvbdev.c\" appears to be a part of a CVE (Common Vulnerabilities and Exposures) information, specifically a use-after-free vulnerability found in the Linux kernel through version 6.0.9. This issue is related to the `dvb_register_device` function that dynamically allocates fops.\n",
      "\n",
      "The text seems to be a part of a dataframe in the source_dfs list, which is used as input for a pipeline in the given code snippet. It is not directly related to the copyrights, licenses, or the configuration of the pipeline.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "====Pipeline Complete====\n",
      "Pipeline complete\n",
      "Pipeline complete. Received 1 responses:\n",
      "\"\"\n",
      "0    Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\n",
      "1    Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\n",
      "2    Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\n",
      "3    Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\n",
      "4    Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\n",
      "Name: response, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Code for batching multiple requets\n",
    "await run_cve_pipeline(pipeline_config, engine_config_custom_model, [\n",
    "    \"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\"\n",
    "] * 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d66334a9",
   "metadata": {},
   "source": [
    "### Creating a Microservice\n",
    "\n",
    "This section will show how to convert the development pipeline into a microservice which is capable of handling requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca8d4182",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Code for creating a microservice\n",
    "import time\n",
    "import cudf\n",
    "from cyber_dev_day.pipeline_utils import build_cve_llm_engine\n",
    "from morpheus.messages import ControlMessage\n",
    "from morpheus.messages import MessageMeta\n",
    "from morpheus.pipeline.linear_pipeline import LinearPipeline\n",
    "from morpheus.pipeline.stage_decorator import stage\n",
    "from morpheus.stages.input.http_server_source_stage import HttpServerSourceStage\n",
    "from morpheus.stages.input.in_memory_source_stage import InMemorySourceStage\n",
    "from morpheus.stages.llm.llm_engine_stage import LLMEngineStage\n",
    "from morpheus.stages.output.in_memory_sink_stage import InMemorySinkStage\n",
    "from morpheus.stages.preprocess.deserialize_stage import DeserializeStage\n",
    "from morpheus.utils.concat_df import concat_dataframes\n",
    "from morpheus.utils.http_utils import HTTPMethod\n",
    "\n",
    "async def run_cve_pipeline_microservice(p_config: Config, e_config: EngineConfig):\n",
    "\n",
    "    completion_task = {\"task_type\": \"completion\", \"task_dict\": {\"input_keys\": [\"cve_info\"], }}\n",
    "\n",
    "    pipe = LinearPipeline(p_config)\n",
    "\n",
    "    # expected payload is:\n",
    "    # [{\"cve_info\": <sting>},\n",
    "    #  {\"cve_info\": <sting>},]\n",
    "    pipe.set_source(\n",
    "        HttpServerSourceStage(p_config,\n",
    "                                bind_address=\"0.0.0.0\",\n",
    "                                port=26302,\n",
    "                                endpoint=\"/scan\",\n",
    "                                method=HTTPMethod.POST))\n",
    "\n",
    "    @stage\n",
    "    def print_payload(payload: MessageMeta) -> MessageMeta:\n",
    "        serialized_str = payload.df.to_json(orient='records', lines=True)\n",
    "\n",
    "        logger.info(\"======= Got Request =======\\n%s\\n===========================\", serialized_str)\n",
    "\n",
    "        return payload\n",
    "\n",
    "    pipe.add_stage(print_payload(config=p_config))\n",
    "\n",
    "    pipe.add_stage(DeserializeStage(p_config, message_type=ControlMessage, task_type=\"llm_engine\", task_payload=completion_task))\n",
    "\n",
    "    pipe.add_stage(LLMEngineStage(p_config, engine=build_cve_llm_engine(e_config)))\n",
    "\n",
    "    sink = pipe.add_stage(InMemorySinkStage(p_config))\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    await pipe.run_async()\n",
    "\n",
    "    messages = sink.get_messages()\n",
    "    responses = concat_dataframes(messages)\n",
    "\n",
    "    logger.info(\"Pipeline complete\")\n",
    "\n",
    "    print(\"Pipeline complete. Received %s responses:\\n%s\" % (len(messages), responses['response']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4f87ac9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "====Pipeline Pre-build====\n",
      "====Pre-Building Segment: linear_segment_0====\n",
      "====Pre-Building Segment Complete!====\n",
      "====Pipeline Pre-build Complete!====\n",
      "====Registering Pipeline====\n",
      "====Building Pipeline====\n",
      "====Building Pipeline Complete!====\n",
      "====Registering Pipeline Complete!====\n",
      "====Starting Pipeline====\n",
      "====Building Segment: linear_segment_0====\n",
      "====Pipeline Started====\n",
      "Added source: <from-http-20; HttpServerSourceStage(bind_address=0.0.0.0, port=26302, endpoint=/scan, method=HTTPMethod.POST, accept_status=201, sleep_time=0.1, queue_timeout=5, max_queue_size=None, num_server_threads=None, max_payload_size=10, request_timeout_secs=30, lines=False, stop_after=0)>\n",
      "  └─> morpheus.MessageMeta\n",
      "Added stage: <print_payload-21; WrappedFunctionStage(name=print_payload, on_data_fn=functools.partial(<function run_cve_pipeline_microservice.<locals>.print_payload at 0x7f398809b0a0>), accept_type=<class 'morpheus.messages.message_meta.MessageMeta'>, compute_schema_fn=<function stage.<locals>.wrapper.<locals>.compute_schema_fn at 0x7f398809af80>, needed_columns=None)>\n",
      "  └─ morpheus.MessageMeta -> morpheus.MessageMeta\n",
      "Added stage: <deserialize-22; DeserializeStage(ensure_sliceable_index=True, message_type=<class 'morpheus._lib.messages.ControlMessage'>, task_type=llm_engine, task_payload={'task_type': 'completion', 'task_dict': {'input_keys': ['cve_info']}})>\n",
      "  └─ morpheus.MessageMeta -> morpheus.ControlMessage\n",
      "Added stage: <llm-engine-23; LLMEngineStage(engine=<morpheus._lib.llm.LLMEngine object at 0x7f3968996b30>)>\n",
      "  └─ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "Added stage: <to-mem-24; InMemorySinkStage()>\n",
      "  └─ morpheus.ControlMessage -> morpheus.ControlMessage\n",
      "====Building Segment Complete!====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I20240311 03:39:54.645272  6881 asyncio_runnable.hpp:246] AsyncioRunnable::run() > Creating new event loop\n",
      "I20240311 03:39:54.646185  6881 asyncio_runnable.hpp:259] AsyncioRunnable::run() > Calling run_until_complete() on main_task()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======= Got Request =======\n",
      "{\"cve_info\":\"An issue was discovered in the Linux kernel through 6.0.9. drivers\\/media\\/dvb-core\\/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\"}\n",
      "\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6600/346353228.py:35: DeprecationWarning: Warning the df property returns a copy, please use the copy_dataframe method or the mutable_dataframe context manager to modify the DataFrame in-place instead.\n",
      "  serialized_str = payload.df.to_json(orient='records', lines=True)\n",
      "/opt/conda/envs/morpheus/lib/python3.10/site-packages/cudf/io/json.py:239: UserWarning: Using CPU via Pandas to write JSON dataset\n",
      "  warnings.warn(\"Using CPU via Pandas to write JSON dataset\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel version is affected by this issue and if the vulnerable file is present in the container.\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFalse\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe SBOM Package Checker returned False, which means the Linux kernel is not present in the Docker container's software bill of materials. Therefore, I cannot determine if the container's Linux kernel version is affected by the issue. However, I can still check if the vulnerable file is present in the container.\n",
      "\n",
      "Action: Docker Container Code QA System\n",
      "Action Input: drivers/media/dvb-core/dvbdev.c\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe string \"drivers/media/dvb-core/dvbdev.c\" appears to be a part of a CVE (Common Vulnerabilities and Exposures) information, specifically a use-after-free vulnerability found in the Linux kernel through version 6.0.9. This issue is related to the `dvb_register_device` function that dynamically allocates fops.\n",
      "\n",
      "The text seems to be a part of a dataframe in the source_dfs list, which is used as input for a pipeline in the given code snippet. It is not directly related to the copyrights, licenses, or the configuration of the pipeline.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "======= Got Request =======\n",
      "{\"cve_info\":\"An issue was discovered in the Linux kernel through 6.0.9. drivers\\/media\\/dvb-core\\/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\"}\n",
      "\n",
      "===========================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6600/346353228.py:35: DeprecationWarning: Warning the df property returns a copy, please use the copy_dataframe method or the mutable_dataframe context manager to modify the DataFrame in-place instead.\n",
      "  serialized_str = payload.df.to_json(orient='records', lines=True)\n",
      "/opt/conda/envs/morpheus/lib/python3.10/site-packages/cudf/io/json.py:239: UserWarning: Using CPU via Pandas to write JSON dataset\n",
      "  warnings.warn(\"Using CPU via Pandas to write JSON dataset\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI need to check if the Docker container's Linux kernel version is affected by this issue and if the vulnerable file is present in the container.\n",
      "Action: SBOM Package Checker\n",
      "Action Input: Linux kernel\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mFalse\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mThe SBOM Package Checker returned False, which means the Linux kernel is not present in the Docker container's software bill of materials. Therefore, I cannot determine if the container's Linux kernel version is affected by the issue. However, I can still check if the vulnerable file is present in the container.\n",
      "\n",
      "Action: Docker Container Code QA System\n",
      "Action Input: drivers/media/dvb-core/dvbdev.c\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mThe string \"drivers/media/dvb-core/dvbdev.c\" appears to be a part of a CVE (Common Vulnerabilities and Exposures) information, specifically a use-after-free vulnerability found in the Linux kernel through version 6.0.9. This issue is related to the `dvb_register_device` function that dynamically allocates fops.\n",
      "\n",
      "The text seems to be a part of a dataframe in the source_dfs list, which is used as input for a pipeline in the given code snippet. It is not directly related to the copyrights, licenses, or the configuration of the pipeline.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
      "Final Answer: Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Stopping pipeline. Please wait... Press Ctrl+C again to kill.\n",
      "====Stopping Pipeline====\n",
      "====Pipeline Stopped====\n",
      "====Pipeline Complete====\n",
      "Pipeline complete\n",
      "Pipeline complete. Received 2 responses:\n",
      "\"\"\n",
      "0    Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\n",
      "0    Based on the information provided, I cannot determine the Linux kernel version in the Docker container. However, the vulnerable file \"drivers/media/dvb-core/dvbdev.c\" appears to be part of the Docker container's codebase. Therefore, it is possible that the container is affected by the use-after-free vulnerability related to `dvb_register_device`. It is recommended to update the Linux kernel to a non-vulnerable version or apply patches to mitigate the risk.\n",
      "Name: response, dtype: object\n"
     ]
    }
   ],
   "source": [
    "await run_cve_pipeline_microservice(pipeline_config, engine_config_custom_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb51d69",
   "metadata": {},
   "source": [
    "##### Triggering the Microservice\n",
    "\n",
    "To trigger the microservice, we will use a CURL request to send a request to the microservice. Since the notebook cannot run commands while the microservice is running, we need to open up a new terminal to send the request. To do that, follow the steps below:\n",
    "\n",
    "1. In Jupyter Lab, press Ctrl + Shift + L (Shift + ⌘ + L on Mac) to open a new Launcher tab\n",
    "2. In the Launcher tab, click on the Terminal icon to open a new terminal\n",
    "3. In the terminal, run the following command to send a request to the microservice:\n",
    "```bash\n",
    "curl --request POST \\\n",
    "  --url http://localhost:26302/scan \\\n",
    "  --header 'Content-Type: application/json' \\\n",
    "  --data '[{\n",
    "      \"cve_info\" : \"An issue was discovered in the Linux kernel through 6.0.9. drivers/media/dvb-core/dvbdev.c has a use-after-free, related to dvb_register_device dynamically allocating fops.\"\n",
    "   }]'\n",
    "```\n",
    "4. Once the request is sent, the microservice will process the request and return the results in the terminal\n",
    "   1. To see the results, switch back to the Notebook tab. You should see that the microservice received your request and started processing it.\n",
    "   ```\n",
    "   I20240308 16:00:56.422039 3010283 http_server.cpp:129] Received request: POST : /scan\n",
    "   ```\n",
    "   2. It helps to have the terminal and the notebook side by side so you can see the results in the terminal as they come in. To do this, click on the terminal tab and drag it to the right side of the screen. You should then be able to see the terminal and the notebook side by side similar to the image below:\n",
    "   ![Terminal and Notebook Side by Side](./images/side_by_side.png)\n",
    "5. To stop the microservice, interrupt the kernel by pressing the stop button in the toolbar"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
