{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Phishing Detection Using BERT- Fine-tuning notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents \n",
    "* Introduction\n",
    "* List of datasets used\n",
    "* Reading in the datasets\n",
    "* Initialize CLX Phishing Detection and BERT model\n",
    "* Training with three datasets CLAIR+SPAM_ASSASSIN+ENRON\n",
    "* Evaluation of the Test Set of CLAIR+SPAM_ASSASSIN+ENRON Datasets\n",
    "* References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Phishing is a method used by fraudsters/hackers to obtain sensitive information from email users by pretending to be from legitimate institutions/people.\n",
    "Various machine learning methods are in use to detect and filter phishing/spam emails. \n",
    "In this notebook, we show how to train a *BERT language model and analyse the performance on various datasets. We have fine-tuned a pre-trained BERT model with a classification layer using HuggingFace library. \n",
    "*BERT stands for Bidirectional Encoder Representations from Transformers. The paper can be found [here.](https://arxiv.org/pdf/1810.04805.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets used\n",
    "* [CLAIR-Fraudulent E-mail Corpus](https://www.kaggle.com/rtatman/fraudulent-email-corpus)\n",
    "* [SPAM_ASSASSIN Dataset](https://spamassassin.apache.org/old/publiccorpus/)\n",
    "* [Enron Emails](https://www.cs.cmu.edu/~enron/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cudf;\n",
    "from cuml.model_selection import train_test_split;\n",
    "from binary_sequence_classifier import BinarySequenceClassifier;\n",
    "import argparse;\n",
    "import s3fs;\n",
    "from os import path;\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAIR_TSV = \"Phishing_Dataset_Clair_Collection.tsv\"\n",
    "SPAM_TSV = \"spam_assassin_spam_200_20021010.tsv\"\n",
    "EASY_HAM_TSV = \"spam_assassin_easyham_200_20021010.tsv\"\n",
    "HARD_HAM_TSV = \"spam_assassin_hardham_200_20021010.tsv\"\n",
    "ENRON_TSV = \"enron_10000.tsv\"\n",
    "S3_BASE_PATH = \"rapidsai-data/cyber/clx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clair dataset\n",
    "if not path.exists(CLAIR_TSV):\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    fs.get(S3_BASE_PATH + \"/\" + CLAIR_TSV, CLAIR_TSV)\n",
    "    \n",
    "dfclair = cudf.read_csv(CLAIR_TSV, delimiter='\\t', header=None, names=['label', 'email']).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phishing emails of the SPAM ASSASSIN dataset\n",
    "if not path.exists(SPAM_TSV):\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    fs.get(S3_BASE_PATH + \"/\" + SPAM_TSV, SPAM_TSV)\n",
    " \n",
    "dfspam = cudf.read_csv(SPAM_TSV, delimiter='\\t', header=None, names=['label', 'email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benign emails of the SPAM ASSASSIN dataset\n",
    "if not path.exists(EASY_HAM_TSV):\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    fs.get(S3_BASE_PATH + \"/\" + EASY_HAM_TSV, EASY_HAM_TSV)\n",
    "    \n",
    "dfeasyham = cudf.read_csv(EASY_HAM_TSV, delimiter='\\t', header=None, names=['label', 'email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benign emails of the SPAM ASSASSIN dataset that are easy to be confused with phishing emails\n",
    "if not path.exists(HARD_HAM_TSV):\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    fs.get(S3_BASE_PATH + \"/\" + HARD_HAM_TSV, HARD_HAM_TSV)\n",
    "\n",
    "dfhardham = cudf.read_csv(HARD_HAM_TSV, delimiter='\\t', header=None, names=['label', 'email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benign Enron emails\n",
    "if not path.exists(ENRON_TSV):\n",
    "    fs = s3fs.S3FileSystem(anon=True)\n",
    "    fs.get(S3_BASE_PATH + \"/\" + ENRON_TSV, ENRON_TSV)\n",
    "\n",
    "dfenron = cudf.read_csv(ENRON_TSV, delimiter='\\t', header=None, names=['label', 'email'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The files contain the first 200 words of each email. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize/Load BERT model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will initialize the sequence classifier module with a pre-trained BERT model. The pre-trained model we use is located at https://huggingface.co/bert-base-uncased For more information on the model, please see the paper at https://arxiv.org/pdf/2005.01634.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "seq_classifier = BinarySequenceClassifier()\n",
    "seq_classifier.init_model(\"bert-base-uncased\")\n",
    "\n",
    "# init_model can also load pre-trained model by passing it model directory path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training with CLAIR+SPAM_ASSASSIN+ENRON datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clair fraudulent e-mails contain criminally deceptive information, usually with the intent of convincing the recipient to give the sender a large amount of money. The original dataset can be found [here](https://www.kaggle.com/rtatman/fraudulent-email-corpus)\n",
    "\n",
    "SPAM_ASSASIN public mail corpus consists of three classes. The first category is \\\"easy ham\\\" which has benign emails; the second category is \\\"hard ham\\\" which has emails which are benign but are closer to spam, and finally, the spam category that includes the fraudulent emails. More info [here](https://spamassassin.apache.org/old/publiccorpus/readme.html)\n",
    "\n",
    "Enron Email Dataset was collected and prepared by the CALO Project (A Cognitive Assistant that Learns and Organizes). We use them as benign email class. \n",
    "More info on the ENRON Email Dataset can be found [here](https://www.cs.cmu.edu/~./enron/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge all the datasets, split into training and test set and then tokenize the emails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = cudf.concat([dfhardham,dfeasyham,dfspam,dfclair,dfenron],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_total, 'label', train_size=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|███▎      | 1/3 [02:34<05:08, 154.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.061520517534322125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████▋   | 2/3 [05:08<02:33, 154.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.011529590881415499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|██████████| 3/3 [07:42<00:00, 154.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.006090488108963731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "seq_classifier.train_model(X_train[\"email\"], y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_classifier.save_model(\"./phish-bert-20211006\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation of the Test Set of CLAIR+SPAM_ASSASSIN+ENRON Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9968354430379747"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_classifier.evaluate_model(X_test[\"email\"], y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When all three datasets are combined, over 99% of the emails are labelled correctly. This shows that using a BERT-based phishing detector performs well in identifying the spam emails across these datasets. This notebook is prepared as a POC. Users can experiment with other datasets, increase the coverage and change the number of epochs to fine-tune the results on their datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "* Radev, D. (2008), CLAIR collection of fraud email, ACL Data and Code Repository, ADCR2008T001, http://aclweb.org/aclwiki\n",
    "* https://www.kaggle.com/rtatman/fraudulent-email-corpus *\n",
    "* https://www.cs.cmu.edu/~./enron/\n",
    "* https://spamassassin.apache.org/old/publiccorpus/readme.html\n",
    "* https://github.com/huggingface/transformers/tree/master/examples#\n",
    "* https://www.depends-on-the-definition.com/named-entity-recognition-with-bert/\n",
    "* https://github.com/ThilinaRajapakse/pytorch-transformers-classification\n",
    "* https://mccormickml.com/2019/07/22/BERT-fine-tuning/"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of BERT Fine-Tuning Sentence Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
